{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "> This tutorial is available as a Jupyter notebook [here](https://github.com/Future-House/paper-qa/blob/main/docs/tutorials/settings_tutorial.ipynb).\n",
    "\n",
    "This tutorial aims to show how to use the `Settings` class to configure `PaperQA`.\n",
    "Firstly, we will be using `OpenAI` and `Anthropic` models, so we need to set the `OPENAI_API_KEY` and `ANTHROPIC_API_KEY` environment variables.\n",
    "We will use both models to make it clear when `paperqa` agent is using either one or the other.\n",
    "We use `python-dotenv` to load the environment variables from a `.env` file.\n",
    "Hence, our first step is to create a `.env` file and install the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fmt: off\n",
    "# Create .env file with OpenAI API and Anthropic API keys\n",
    "# Replace <your-openai-api-key> and <your-anthropic-api-key> with your actual API keys\n",
    "!echo \"OPENAI_API_KEY=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\" > .env # fmt: skip\n",
    "# !echo \"ANTHROPIC_API_KEY=<your-anthropic-api-key>\" >> .env # fmt: skip\n",
    "\n",
    "!uv pip install -q nest-asyncio python-dotenv aiohttp fhlmi \"paper-qa[local]\"\n",
    "# fmt: on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import aiohttp\n",
    "import nest_asyncio\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "nest_asyncio.apply()\n",
    "load_dotenv(\".env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have set the following environment variables:\n",
      "OPENAI_API_KEY:    is set\n"
     ]
    }
   ],
   "source": [
    "print(\"You have set the following environment variables:\")\n",
    "print(\n",
    "    f\"OPENAI_API_KEY:    {'is set' if os.environ['OPENAI_API_KEY'] else 'is not set'}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the `lmi` package to get the model names and the `.papers` directory to save documents we will use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lmi import CommonLLMNames\n",
    "\n",
    "llm_openai = CommonLLMNames.OPENAI_TEST.value\n",
    "llm_anthropic = CommonLLMNames.ANTHROPIC_TEST.value\n",
    "\n",
    "# Create the `papers` directory if it doesn't exist\n",
    "os.makedirs(\"papers\", exist_ok=True)\n",
    "\n",
    "# Download the paper from arXiv and save it to the `papers` directory\n",
    "url = \"https://arxiv.org/pdf/2407.01603\"\n",
    "async with aiohttp.ClientSession() as session, session.get(url, timeout=60) as response:\n",
    "    content = await response.read()\n",
    "    with open(\"papers/2407.01603.pdf\", \"wb\") as f:\n",
    "        f.write(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Settings` class is used to configure the PaperQA settings.\n",
    "Official documentation can be found [here](https://github.com/Future-House/paper-qa?tab=readme-ov-file#settings-cheatsheet) and the open source code can be found [here](https://github.com/Future-House/paper-qa/blob/main/paperqa/settings.py).\n",
    "\n",
    "Here is a basic example of how to use the `Settings` class. We will be unnecessarily verbose for the sake of clarity. Please notice that most of the settings are optional and the defaults are good for most cases. Refer to the [descriptions of each setting](https://github.com/Future-House/paper-qa/blob/main/paperqa/settings.py) for more information.\n",
    "\n",
    "Within this `Settings` object, I'd like to discuss specifically how the llms are configured and how `paperqa` looks for papers.\n",
    "\n",
    "A common source of confusion is that multiple `llms` are used in paperqa. We have `llm`, `summary_llm`, `agent_llm`, and `embedding`. Hence, if `llm` is set to an `Anthropic` model, `summary_llm` and `agent_llm` will still require a `OPENAI_API_KEY`, since `OpenAI` models are the default.\n",
    "\n",
    "Among the objects that use `llms` in `paperqa`, we have `llm`, `summary_llm`, `agent_llm`, and `embedding`:\n",
    "\n",
    "- `llm`: Main LLM used by the agent to reason about the question, extract metadata from documents, etc.\n",
    "- `summary_llm`: LLM used to summarize the papers.\n",
    "- `agent_llm`: LLM used to answer questions and select tools.\n",
    "- `embedding`: Embedding model used to embed the papers.\n",
    "\n",
    "Let's see some examples around this concept. First, we define the settings with `llm` set to an `OpenAI` model. Please notice this is not an complete list of settings. But take your time to read through this `Settings` class and all customization that can be done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiali03/Desktop/xc392/paper-qa/.venv/lib/python3.13/site-packages/pybtex/plugin/__init__.py:26: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "\n",
    "from paperqa.prompts import (\n",
    "    CONTEXT_INNER_PROMPT,\n",
    "    CONTEXT_OUTER_PROMPT,\n",
    "    citation_prompt,\n",
    "    default_system_prompt,\n",
    "    env_reset_prompt,\n",
    "    env_system_prompt,\n",
    "    qa_prompt,\n",
    "    select_paper_prompt,\n",
    "    structured_citation_prompt,\n",
    "    summary_json_prompt,\n",
    "    summary_json_system_prompt,\n",
    "    summary_prompt,\n",
    ")\n",
    "from paperqa.settings import (\n",
    "    AgentSettings,\n",
    "    AnswerSettings,\n",
    "    IndexSettings,\n",
    "    ParsingSettings,\n",
    "    PromptSettings,\n",
    "    Settings,\n",
    ")\n",
    "\n",
    "settings = Settings(\n",
    "    llm=llm_openai,\n",
    "    llm_config={\n",
    "        \"model_list\": [\n",
    "            {\n",
    "                \"model_name\": llm_openai,\n",
    "                \"litellm_params\": {\n",
    "                    \"model\": llm_openai,\n",
    "                    \"temperature\": 0.1,\n",
    "                    \"max_tokens\": 4096,\n",
    "                },\n",
    "            }\n",
    "        ],\n",
    "        \"rate_limit\": {\n",
    "            llm_openai: \"30000 per 1 minute\",\n",
    "        },\n",
    "    },\n",
    "    summary_llm=llm_openai,\n",
    "    summary_llm_config={\n",
    "        \"rate_limit\": {\n",
    "            llm_openai: \"30000 per 1 minute\",\n",
    "        },\n",
    "    },\n",
    "    embedding=\"text-embedding-3-small\",\n",
    "    embedding_config={},\n",
    "    temperature=0.1,\n",
    "    batch_size=1,\n",
    "    verbosity=1,\n",
    "    manifest_file=None,\n",
    "    paper_directory=pathlib.Path.cwd().joinpath(\"papers\"),\n",
    "    index_directory=pathlib.Path.cwd().joinpath(\"papers/index\"),\n",
    "    answer=AnswerSettings(\n",
    "        evidence_k=10,\n",
    "        evidence_detailed_citations=True,\n",
    "        evidence_retrieval=True,\n",
    "        evidence_summary_length=\"about 100 words\",\n",
    "        evidence_skip_summary=False,\n",
    "        answer_max_sources=5,\n",
    "        max_answer_attempts=None,\n",
    "        answer_length=\"about 200 words, but can be longer\",\n",
    "        max_concurrent_requests=10,\n",
    "    ),\n",
    "    parsing=ParsingSettings(\n",
    "        chunk_size=5000,\n",
    "        overlap=250,\n",
    "        citation_prompt=citation_prompt,\n",
    "        structured_citation_prompt=structured_citation_prompt,\n",
    "    ),\n",
    "    prompts=PromptSettings(\n",
    "        summary=summary_prompt,\n",
    "        qa=qa_prompt,\n",
    "        select=select_paper_prompt,\n",
    "        pre=None,\n",
    "        post=None,\n",
    "        system=default_system_prompt,\n",
    "        use_json=True,\n",
    "        summary_json=summary_json_prompt,\n",
    "        summary_json_system=summary_json_system_prompt,\n",
    "        context_outer=CONTEXT_OUTER_PROMPT,\n",
    "        context_inner=CONTEXT_INNER_PROMPT,\n",
    "    ),\n",
    "    agent=AgentSettings(\n",
    "        agent_llm=llm_openai,\n",
    "        agent_llm_config={\n",
    "            \"model_list\": [\n",
    "                {\n",
    "                    \"model_name\": llm_openai,\n",
    "                    \"litellm_params\": {\n",
    "                        \"model\": llm_openai,\n",
    "                    },\n",
    "                }\n",
    "            ],\n",
    "            \"rate_limit\": {\n",
    "                llm_openai: \"30000 per 1 minute\",\n",
    "            },\n",
    "        },\n",
    "        agent_prompt=env_reset_prompt,\n",
    "        agent_system_prompt=env_system_prompt,\n",
    "        search_count=8,\n",
    "        index=IndexSettings(\n",
    "            paper_directory=pathlib.Path.cwd().joinpath(\"papers\"),\n",
    "            index_directory=pathlib.Path.cwd().joinpath(\"papers/index\"),\n",
    "        ),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it is evident, `Paperqa` is absolutely customizable. And here we reinterate that despite this possible fine customization, the defaults are good for most cases. Although, the user is welcome to explore the settings and customize the `paperqa` to their needs.\n",
    "\n",
    "We also set settings.verbosity to 1, which will print the agent configuration. Feel free to set it to 0 to silence the logging after your first run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PaperQA version: 5.21.1.dev17+g2cf0d6c\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[00:32:53] </span>Beginning agent <span style=\"color: #008000; text-decoration-color: #008000\">'ToolSelector'</span> run with question <span style=\"color: #008000; text-decoration-color: #008000\">'What are the most relevant language models used for </span>  \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">chemistry?'</span> and full settings <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'llm'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini-2024-07-18'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'llm_config'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'model_list'</span>:            \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"font-weight: bold\">[{</span><span style=\"color: #008000; text-decoration-color: #008000\">'model_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini-2024-07-18'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'litellm_params'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini-2024-07-18'</span>,         \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">'temperature'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'max_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4096</span><span style=\"font-weight: bold\">}}]</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'rate_limit'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini-2024-07-18'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'30000 per 1 </span>       \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">minute'</span><span style=\"font-weight: bold\">}}</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'summary_llm'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini-2024-07-18'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'summary_llm_config'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'rate_limit'</span>:                \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini-2024-07-18'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'30000 per 1 minute'</span><span style=\"font-weight: bold\">}}</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'embedding'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'text-embedding-3-small'</span>,               \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">'embedding_config'</span>: <span style=\"font-weight: bold\">{}</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'temperature'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'batch_size'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'texts_index_mmr_lambda'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'verbosity'</span>:\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'answer'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'evidence_k'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'evidence_detailed_citations'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'evidence_retrieval'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,        \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">'evidence_summary_length'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'about 100 words'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'evidence_skip_summary'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'answer_max_sources'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>,  \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">'max_answer_attempts'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'answer_length'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'about 200 words, but can be longer'</span>,                     \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">'max_concurrent_requests'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'answer_filter_extra_background'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'get_evidence_if_no_contexts'</span>:  \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">}</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'parsing'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'chunk_size'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5000</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'page_size_limit'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1280000</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'pdfs_use_block_parsing'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,     \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">'use_doc_details'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'overlap'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">250</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'citation_prompt'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Provide the citation for the following text</span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">in MLA Format. Do not write an introductory sentence. If reporting date accessed, the current year is </span>  \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">2025\\n\\n{text}\\n\\nCitation:'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'structured_citation_prompt'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Extract the title, authors, and doi as a </span>  \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">JSON from this MLA citation. If any field can not be found, return it as null. Use title, authors, and </span> \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">doi as keys, author's value should be a list of authors. {citation}\\n\\nCitation JSON:\"</span>,                 \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">'disable_doc_valid_check'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'defer_embedding'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'chunking_algorithm'</span>:                       \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">ChunkingOptions.SIMPLE_OVERLAP:</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span><span style=\"color: #008000; text-decoration-color: #008000\">'simple_overlap'</span><span style=\"font-weight: bold\">&gt;</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'doc_filters'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,                                \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">'use_human_readable_clinical_trials'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">}</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'prompts'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'summary'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Summarize the excerpt below to </span>   \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">help answer a question.\\n\\nExcerpt from {citation}\\n\\n----\\n\\n{text}\\n\\n----\\n\\nQuestion: </span>              \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">{question}\\n\\nDo not directly answer the question, instead summarize to give evidence to help answer the</span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">question. Stay detailed; report specific numbers, equations, or direct quotes (marked with quotation </span>   \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">marks). Reply \"Not applicable\" if the excerpt is irrelevant. At the end of your response, provide an </span>   \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">integer score from 1-10 on a newline indicating relevance to question. Do not explain your </span>             \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">score.\\n\\nRelevant Information Summary ({summary_length}):'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'qa'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Answer the question below with the </span> \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">context.\\n\\nContext (with relevance scores):\\n\\n{context}\\n\\n----\\n\\nQuestion: {question}\\n\\nWrite an </span>  \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">answer based on the context. If the context provides insufficient information reply \"I cannot answer.\" </span> \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">For each part of your answer, indicate which sources most support it via citation keys at the end of </span>   \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">sentences, like {example_citation}. Only cite from the context above and only use the citation keys from</span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">the context. ## Valid citation examples: \\n- Example2024Example pages 3-4 \\n- Example2024 pages 3-4 \\n- </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">Example2024 pages 3-4, Example2024 pages 5-6 \\n## Invalid citation examples: \\n- Example2024Example </span>    \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">pages 3-4 and pages 4-5 \\n- Example2024Example (pages 3-4) \\n- Example2024Example pages 3-4, pages 5-6 </span> \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">\\n- Example2024Example et al. (2024) \\n- Example\\'s work (pages 17–19) \\n- (pages 17–19) \\nDo not </span>      \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">concatenate citation keys, just use them as is. Write in the style of a Wikipedia article, with concise </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">sentences and coherent paragraphs. The context comes from a variety of sources and is only a summary, so</span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">there may inaccuracies or ambiguities. If quotes are present and relevant, use them in the answer. This </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">answer will go directly onto Wikipedia, so do not add any extraneous </span>                                   \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">information.\\n\\n{prior_answer_prompt}Answer ({answer_length}):'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'answer_iteration_prompt'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'You are </span>   \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">iterating on a prior answer, with a potentially different context:\\n\\n{prior_answer}\\n\\nCreate a new </span>   \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">answer only using keys and data from the included context. You can not use context keys from the prior </span> \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">answer which are not also included in the above context.\\n\\n'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'select'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Select papers that may help </span>  \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">answer the question below. Papers are listed as $KEY: $PAPER_INFO. Return a list of keys, separated by </span> \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">commas. Return \"None\", if no papers are applicable. Choose papers that are relevant, from reputable </span>    \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">sources, and timely (if the question requires timely information).\\n\\nQuestion: {question}\\n\\nPapers: </span>  \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">{papers}\\n\\nSelected keys:'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'pre'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'post'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'system'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Answer in a direct and concise tone. </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">Your audience is an expert, so be highly specific. If there are ambiguous terms or acronyms, first </span>     \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">define them.'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'use_json'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'summary_json'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Excerpt from </span>                                         \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">{citation}\\n\\n----\\n\\n{text}\\n\\n----\\n\\nQuestion: {question}\\n\\n'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'summary_json_system'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Provide a </span>   \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">summary of the relevant information that could help answer the question based on the excerpt. Respond </span>  \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">with the following JSON format:\\n\\n{{\\n  \"summary\": \"...\",\\n  \"relevance_score\": \"...\"\\n}}\\n\\nwhere </span>    \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">`summary` is relevant information from the text - {summary_length} words. `relevance_score` is an </span>      \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">integer 1-10 for the relevance of `summary` to the question.\\n'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'context_outer'</span>:                       \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">'{context_str}\\n\\nValid Keys: {valid_keys}'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'context_inner'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'{name}: {text}\\nFrom {citation}'</span><span style=\"font-weight: bold\">}</span>,       \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">'agent'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'agent_llm'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini-2024-07-18'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'agent_llm_config'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'model_list'</span>: <span style=\"font-weight: bold\">[{</span><span style=\"color: #008000; text-decoration-color: #008000\">'model_name'</span>:     \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini-2024-07-18'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'litellm_params'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini-2024-07-18'</span><span style=\"font-weight: bold\">}}]</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'rate_limit'</span>:        \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini-2024-07-18'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'30000 per 1 minute'</span><span style=\"font-weight: bold\">}}</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'agent_type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'ToolSelector'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'agent_config'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,  \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">'agent_system_prompt'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'You are a helpful AI assistant.'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'agent_prompt'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Use the tools to answer the </span> \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">question: {question}\\n\\nWhen the answer looks sufficient, you can terminate by calling the </span>             \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">{complete_tool_name} tool. If the answer does not look sufficient, and you have already tried to answer </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">several times with different evidence, terminate by calling the {complete_tool_name} tool. The current </span> \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">status of evidence/papers/cost is {status}'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'return_paper_metadata'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'search_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>,         \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">'wipe_context_on_answer_failure'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'agent_evidence_n'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'timeout'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">500.0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'should_pre_search'</span>:   \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'tool_names'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'max_timesteps'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'index'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'paper_directory'</span>:            \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PosixPath</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'/Users/jiali03/Desktop/xc392/paper-qa/docs/tutorials/papers'</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'manifest_file'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,        \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">'index_directory'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PosixPath</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'/Users/jiali03/Desktop/xc392/paper-qa/docs/tutorials/papers/index'</span><span style=\"font-weight: bold\">)</span>,      \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">'use_absolute_paper_directory'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'recurse_subdirectories'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'concurrency'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'batch_size'</span>:  \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'sync_with_paper_directory'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">}</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'rebuild_index'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">}</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'md5'</span>:                                   \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">'fb017488f008b9a3f53fb44eaa50eeb3'</span><span style=\"font-weight: bold\">}</span>.                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[00:32:53]\u001b[0m\u001b[2;36m \u001b[0mBeginning agent \u001b[32m'ToolSelector'\u001b[0m run with question \u001b[32m'What are the most relevant language models used for \u001b[0m  \n",
       "\u001b[2;36m           \u001b[0m\u001b[32mchemistry?'\u001b[0m and full settings \u001b[1m{\u001b[0m\u001b[32m'llm'\u001b[0m: \u001b[32m'gpt-4o-mini-2024-07-18'\u001b[0m, \u001b[32m'llm_config'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'model_list'\u001b[0m:            \n",
       "\u001b[2;36m           \u001b[0m\u001b[1m[\u001b[0m\u001b[1m{\u001b[0m\u001b[32m'model_name'\u001b[0m: \u001b[32m'gpt-4o-mini-2024-07-18'\u001b[0m, \u001b[32m'litellm_params'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'model'\u001b[0m: \u001b[32m'gpt-4o-mini-2024-07-18'\u001b[0m,         \n",
       "\u001b[2;36m           \u001b[0m\u001b[32m'temperature'\u001b[0m: \u001b[1;36m0.1\u001b[0m, \u001b[32m'max_tokens'\u001b[0m: \u001b[1;36m4096\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'rate_limit'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'gpt-4o-mini-2024-07-18'\u001b[0m: \u001b[32m'30000 per 1 \u001b[0m       \n",
       "\u001b[2;36m           \u001b[0m\u001b[32mminute'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'summary_llm'\u001b[0m: \u001b[32m'gpt-4o-mini-2024-07-18'\u001b[0m, \u001b[32m'summary_llm_config'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'rate_limit'\u001b[0m:                \n",
       "\u001b[2;36m           \u001b[0m\u001b[1m{\u001b[0m\u001b[32m'gpt-4o-mini-2024-07-18'\u001b[0m: \u001b[32m'30000 per 1 minute'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'embedding'\u001b[0m: \u001b[32m'text-embedding-3-small'\u001b[0m,               \n",
       "\u001b[2;36m           \u001b[0m\u001b[32m'embedding_config'\u001b[0m: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'temperature'\u001b[0m: \u001b[1;36m0.1\u001b[0m, \u001b[32m'batch_size'\u001b[0m: \u001b[1;36m1\u001b[0m, \u001b[32m'texts_index_mmr_lambda'\u001b[0m: \u001b[1;36m1.0\u001b[0m, \u001b[32m'verbosity'\u001b[0m:\n",
       "\u001b[2;36m           \u001b[0m\u001b[1;36m1\u001b[0m, \u001b[32m'answer'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'evidence_k'\u001b[0m: \u001b[1;36m10\u001b[0m, \u001b[32m'evidence_detailed_citations'\u001b[0m: \u001b[3;92mTrue\u001b[0m, \u001b[32m'evidence_retrieval'\u001b[0m: \u001b[3;92mTrue\u001b[0m,        \n",
       "\u001b[2;36m           \u001b[0m\u001b[32m'evidence_summary_length'\u001b[0m: \u001b[32m'about 100 words'\u001b[0m, \u001b[32m'evidence_skip_summary'\u001b[0m: \u001b[3;91mFalse\u001b[0m, \u001b[32m'answer_max_sources'\u001b[0m: \u001b[1;36m5\u001b[0m,  \n",
       "\u001b[2;36m           \u001b[0m\u001b[32m'max_answer_attempts'\u001b[0m: \u001b[3;35mNone\u001b[0m, \u001b[32m'answer_length'\u001b[0m: \u001b[32m'about 200 words, but can be longer'\u001b[0m,                     \n",
       "\u001b[2;36m           \u001b[0m\u001b[32m'max_concurrent_requests'\u001b[0m: \u001b[1;36m10\u001b[0m, \u001b[32m'answer_filter_extra_background'\u001b[0m: \u001b[3;91mFalse\u001b[0m, \u001b[32m'get_evidence_if_no_contexts'\u001b[0m:  \n",
       "\u001b[2;36m           \u001b[0m\u001b[3;92mTrue\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'parsing'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'chunk_size'\u001b[0m: \u001b[1;36m5000\u001b[0m, \u001b[32m'page_size_limit'\u001b[0m: \u001b[1;36m1280000\u001b[0m, \u001b[32m'pdfs_use_block_parsing'\u001b[0m: \u001b[3;91mFalse\u001b[0m,     \n",
       "\u001b[2;36m           \u001b[0m\u001b[32m'use_doc_details'\u001b[0m: \u001b[3;92mTrue\u001b[0m, \u001b[32m'overlap'\u001b[0m: \u001b[1;36m250\u001b[0m, \u001b[32m'citation_prompt'\u001b[0m: \u001b[32m'Provide the citation for the following text\u001b[0m\n",
       "\u001b[2;36m           \u001b[0m\u001b[32min MLA Format. Do not write an introductory sentence. If reporting date accessed, the current year is \u001b[0m  \n",
       "\u001b[2;36m           \u001b[0m\u001b[32m2025\\n\\n\u001b[0m\u001b[32m{\u001b[0m\u001b[32mtext\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\\nCitation:'\u001b[0m, \u001b[32m'structured_citation_prompt'\u001b[0m: \u001b[32m\"Extract the title, authors, and doi as a \u001b[0m  \n",
       "\u001b[2;36m           \u001b[0m\u001b[32mJSON from this MLA citation. If any field can not be found, return it as null. Use title, authors, and \u001b[0m \n",
       "\u001b[2;36m           \u001b[0m\u001b[32mdoi as keys, author's value should be a list of authors. \u001b[0m\u001b[32m{\u001b[0m\u001b[32mcitation\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\\nCitation JSON:\"\u001b[0m,                 \n",
       "\u001b[2;36m           \u001b[0m\u001b[32m'disable_doc_valid_check'\u001b[0m: \u001b[3;91mFalse\u001b[0m, \u001b[32m'defer_embedding'\u001b[0m: \u001b[3;91mFalse\u001b[0m, \u001b[32m'chunking_algorithm'\u001b[0m:                       \n",
       "\u001b[2;36m           \u001b[0m\u001b[1m<\u001b[0m\u001b[1;95mChunkingOptions.SIMPLE_OVERLAP:\u001b[0m\u001b[39m \u001b[0m\u001b[32m'simple_overlap'\u001b[0m\u001b[1m>\u001b[0m, \u001b[32m'doc_filters'\u001b[0m: \u001b[3;35mNone\u001b[0m,                                \n",
       "\u001b[2;36m           \u001b[0m\u001b[32m'use_human_readable_clinical_trials'\u001b[0m: \u001b[3;91mFalse\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'prompts'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'summary'\u001b[0m: \u001b[32m'Summarize the excerpt below to \u001b[0m   \n",
       "\u001b[2;36m           \u001b[0m\u001b[32mhelp answer a question.\\n\\nExcerpt from \u001b[0m\u001b[32m{\u001b[0m\u001b[32mcitation\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\\n----\\n\\n\u001b[0m\u001b[32m{\u001b[0m\u001b[32mtext\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\\n----\\n\\nQuestion: \u001b[0m              \n",
       "\u001b[2;36m           \u001b[0m\u001b[32m{\u001b[0m\u001b[32mquestion\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\\nDo not directly answer the question, instead summarize to give evidence to help answer the\u001b[0m\n",
       "\u001b[2;36m           \u001b[0m\u001b[32mquestion. Stay detailed; report specific numbers, equations, or direct quotes \u001b[0m\u001b[32m(\u001b[0m\u001b[32mmarked with quotation \u001b[0m   \n",
       "\u001b[2;36m           \u001b[0m\u001b[32mmarks\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. Reply \"Not applicable\" if the excerpt is irrelevant. At the end of your response, provide an \u001b[0m   \n",
       "\u001b[2;36m           \u001b[0m\u001b[32minteger score from 1-10 on a newline indicating relevance to question. Do not explain your \u001b[0m             \n",
       "\u001b[2;36m           \u001b[0m\u001b[32mscore.\\n\\nRelevant Information Summary \u001b[0m\u001b[32m(\u001b[0m\u001b[32m{\u001b[0m\u001b[32msummary_length\u001b[0m\u001b[32m}\u001b[0m\u001b[32m)\u001b[0m\u001b[32m:'\u001b[0m, \u001b[32m'qa'\u001b[0m: \u001b[32m'Answer the question below with the \u001b[0m \n",
       "\u001b[2;36m           \u001b[0m\u001b[32mcontext.\\n\\nContext \u001b[0m\u001b[32m(\u001b[0m\u001b[32mwith relevance scores\u001b[0m\u001b[32m)\u001b[0m\u001b[32m:\\n\\n\u001b[0m\u001b[32m{\u001b[0m\u001b[32mcontext\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\\n----\\n\\nQuestion: \u001b[0m\u001b[32m{\u001b[0m\u001b[32mquestion\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\\nWrite an \u001b[0m  \n",
       "\u001b[2;36m           \u001b[0m\u001b[32manswer based on the context. If the context provides insufficient information reply \"I cannot answer.\" \u001b[0m \n",
       "\u001b[2;36m           \u001b[0m\u001b[32mFor each part of your answer, indicate which sources most support it via citation keys at the end of \u001b[0m   \n",
       "\u001b[2;36m           \u001b[0m\u001b[32msentences, like \u001b[0m\u001b[32m{\u001b[0m\u001b[32mexample_citation\u001b[0m\u001b[32m}\u001b[0m\u001b[32m. Only cite from the context above and only use the citation keys from\u001b[0m\n",
       "\u001b[2;36m           \u001b[0m\u001b[32mthe context. ## Valid citation examples: \\n- Example2024Example pages 3-4 \\n- Example2024 pages 3-4 \\n- \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m\u001b[32mExample2024 pages 3-4, Example2024 pages 5-6 \\n## Invalid citation examples: \\n- Example2024Example \u001b[0m    \n",
       "\u001b[2;36m           \u001b[0m\u001b[32mpages 3-4 and pages 4-5 \\n- Example2024Example \u001b[0m\u001b[32m(\u001b[0m\u001b[32mpages 3-4\u001b[0m\u001b[32m)\u001b[0m\u001b[32m \\n- Example2024Example pages 3-4, pages 5-6 \u001b[0m \n",
       "\u001b[2;36m           \u001b[0m\u001b[32m\\n- Example2024Example et al. \u001b[0m\u001b[32m(\u001b[0m\u001b[32m2024\u001b[0m\u001b[32m)\u001b[0m\u001b[32m \\n- Example\\'s work \u001b[0m\u001b[32m(\u001b[0m\u001b[32mpages 17–19\u001b[0m\u001b[32m)\u001b[0m\u001b[32m \\n- \u001b[0m\u001b[32m(\u001b[0m\u001b[32mpages 17–19\u001b[0m\u001b[32m)\u001b[0m\u001b[32m \\nDo not \u001b[0m      \n",
       "\u001b[2;36m           \u001b[0m\u001b[32mconcatenate citation keys, just use them as is. Write in the style of a Wikipedia article, with concise \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m\u001b[32msentences and coherent paragraphs. The context comes from a variety of sources and is only a summary, so\u001b[0m\n",
       "\u001b[2;36m           \u001b[0m\u001b[32mthere may inaccuracies or ambiguities. If quotes are present and relevant, use them in the answer. This \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m\u001b[32manswer will go directly onto Wikipedia, so do not add any extraneous \u001b[0m                                   \n",
       "\u001b[2;36m           \u001b[0m\u001b[32minformation.\\n\\n\u001b[0m\u001b[32m{\u001b[0m\u001b[32mprior_answer_prompt\u001b[0m\u001b[32m}\u001b[0m\u001b[32mAnswer \u001b[0m\u001b[32m(\u001b[0m\u001b[32m{\u001b[0m\u001b[32manswer_length\u001b[0m\u001b[32m}\u001b[0m\u001b[32m)\u001b[0m\u001b[32m:'\u001b[0m, \u001b[32m'answer_iteration_prompt'\u001b[0m: \u001b[32m'You are \u001b[0m   \n",
       "\u001b[2;36m           \u001b[0m\u001b[32miterating on a prior answer, with a potentially different context:\\n\\n\u001b[0m\u001b[32m{\u001b[0m\u001b[32mprior_answer\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\\nCreate a new \u001b[0m   \n",
       "\u001b[2;36m           \u001b[0m\u001b[32manswer only using keys and data from the included context. You can not use context keys from the prior \u001b[0m \n",
       "\u001b[2;36m           \u001b[0m\u001b[32manswer which are not also included in the above context.\\n\\n'\u001b[0m, \u001b[32m'select'\u001b[0m: \u001b[32m'Select papers that may help \u001b[0m  \n",
       "\u001b[2;36m           \u001b[0m\u001b[32manswer the question below. Papers are listed as $KEY: $PAPER_INFO. Return a list of keys, separated by \u001b[0m \n",
       "\u001b[2;36m           \u001b[0m\u001b[32mcommas. Return \"None\", if no papers are applicable. Choose papers that are relevant, from reputable \u001b[0m    \n",
       "\u001b[2;36m           \u001b[0m\u001b[32msources, and timely \u001b[0m\u001b[32m(\u001b[0m\u001b[32mif the question requires timely information\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\n\\nQuestion: \u001b[0m\u001b[32m{\u001b[0m\u001b[32mquestion\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\\nPapers: \u001b[0m  \n",
       "\u001b[2;36m           \u001b[0m\u001b[32m{\u001b[0m\u001b[32mpapers\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\\nSelected keys:'\u001b[0m, \u001b[32m'pre'\u001b[0m: \u001b[3;35mNone\u001b[0m, \u001b[32m'post'\u001b[0m: \u001b[3;35mNone\u001b[0m, \u001b[32m'system'\u001b[0m: \u001b[32m'Answer in a direct and concise tone. \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m\u001b[32mYour audience is an expert, so be highly specific. If there are ambiguous terms or acronyms, first \u001b[0m     \n",
       "\u001b[2;36m           \u001b[0m\u001b[32mdefine them.'\u001b[0m, \u001b[32m'use_json'\u001b[0m: \u001b[3;92mTrue\u001b[0m, \u001b[32m'summary_json'\u001b[0m: \u001b[32m'Excerpt from \u001b[0m                                         \n",
       "\u001b[2;36m           \u001b[0m\u001b[32m{\u001b[0m\u001b[32mcitation\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\\n----\\n\\n\u001b[0m\u001b[32m{\u001b[0m\u001b[32mtext\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\\n----\\n\\nQuestion: \u001b[0m\u001b[32m{\u001b[0m\u001b[32mquestion\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\\n'\u001b[0m, \u001b[32m'summary_json_system'\u001b[0m: \u001b[32m'Provide a \u001b[0m   \n",
       "\u001b[2;36m           \u001b[0m\u001b[32msummary of the relevant information that could help answer the question based on the excerpt. Respond \u001b[0m  \n",
       "\u001b[2;36m           \u001b[0m\u001b[32mwith the following JSON format:\\n\\n\u001b[0m\u001b[32m{\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\n  \"summary\": \"...\",\\n  \"relevance_score\": \"...\"\\n\u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\\nwhere \u001b[0m    \n",
       "\u001b[2;36m           \u001b[0m\u001b[32m`summary` is relevant information from the text - \u001b[0m\u001b[32m{\u001b[0m\u001b[32msummary_length\u001b[0m\u001b[32m}\u001b[0m\u001b[32m words. `relevance_score` is an \u001b[0m      \n",
       "\u001b[2;36m           \u001b[0m\u001b[32minteger 1-10 for the relevance of `summary` to the question.\\n'\u001b[0m, \u001b[32m'context_outer'\u001b[0m:                       \n",
       "\u001b[2;36m           \u001b[0m\u001b[32m'\u001b[0m\u001b[32m{\u001b[0m\u001b[32mcontext_str\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\\nValid Keys: \u001b[0m\u001b[32m{\u001b[0m\u001b[32mvalid_keys\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m, \u001b[32m'context_inner'\u001b[0m: \u001b[32m'\u001b[0m\u001b[32m{\u001b[0m\u001b[32mname\u001b[0m\u001b[32m}\u001b[0m\u001b[32m: \u001b[0m\u001b[32m{\u001b[0m\u001b[32mtext\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\nFrom \u001b[0m\u001b[32m{\u001b[0m\u001b[32mcitation\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m\u001b[1m}\u001b[0m,       \n",
       "\u001b[2;36m           \u001b[0m\u001b[32m'agent'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'agent_llm'\u001b[0m: \u001b[32m'gpt-4o-mini-2024-07-18'\u001b[0m, \u001b[32m'agent_llm_config'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'model_list'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m{\u001b[0m\u001b[32m'model_name'\u001b[0m:     \n",
       "\u001b[2;36m           \u001b[0m\u001b[32m'gpt-4o-mini-2024-07-18'\u001b[0m, \u001b[32m'litellm_params'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'model'\u001b[0m: \u001b[32m'gpt-4o-mini-2024-07-18'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'rate_limit'\u001b[0m:        \n",
       "\u001b[2;36m           \u001b[0m\u001b[1m{\u001b[0m\u001b[32m'gpt-4o-mini-2024-07-18'\u001b[0m: \u001b[32m'30000 per 1 minute'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'agent_type'\u001b[0m: \u001b[32m'ToolSelector'\u001b[0m, \u001b[32m'agent_config'\u001b[0m: \u001b[3;35mNone\u001b[0m,  \n",
       "\u001b[2;36m           \u001b[0m\u001b[32m'agent_system_prompt'\u001b[0m: \u001b[32m'You are a helpful AI assistant.'\u001b[0m, \u001b[32m'agent_prompt'\u001b[0m: \u001b[32m'Use the tools to answer the \u001b[0m \n",
       "\u001b[2;36m           \u001b[0m\u001b[32mquestion: \u001b[0m\u001b[32m{\u001b[0m\u001b[32mquestion\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\\nWhen the answer looks sufficient, you can terminate by calling the \u001b[0m             \n",
       "\u001b[2;36m           \u001b[0m\u001b[32m{\u001b[0m\u001b[32mcomplete_tool_name\u001b[0m\u001b[32m}\u001b[0m\u001b[32m tool. If the answer does not look sufficient, and you have already tried to answer \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m\u001b[32mseveral times with different evidence, terminate by calling the \u001b[0m\u001b[32m{\u001b[0m\u001b[32mcomplete_tool_name\u001b[0m\u001b[32m}\u001b[0m\u001b[32m tool. The current \u001b[0m \n",
       "\u001b[2;36m           \u001b[0m\u001b[32mstatus of evidence/papers/cost is \u001b[0m\u001b[32m{\u001b[0m\u001b[32mstatus\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m, \u001b[32m'return_paper_metadata'\u001b[0m: \u001b[3;91mFalse\u001b[0m, \u001b[32m'search_count'\u001b[0m: \u001b[1;36m8\u001b[0m,         \n",
       "\u001b[2;36m           \u001b[0m\u001b[32m'wipe_context_on_answer_failure'\u001b[0m: \u001b[3;92mTrue\u001b[0m, \u001b[32m'agent_evidence_n'\u001b[0m: \u001b[1;36m1\u001b[0m, \u001b[32m'timeout'\u001b[0m: \u001b[1;36m500.0\u001b[0m, \u001b[32m'should_pre_search'\u001b[0m:   \n",
       "\u001b[2;36m           \u001b[0m\u001b[3;91mFalse\u001b[0m, \u001b[32m'tool_names'\u001b[0m: \u001b[3;35mNone\u001b[0m, \u001b[32m'max_timesteps'\u001b[0m: \u001b[3;35mNone\u001b[0m, \u001b[32m'index'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'name'\u001b[0m: \u001b[3;35mNone\u001b[0m, \u001b[32m'paper_directory'\u001b[0m:            \n",
       "\u001b[2;36m           \u001b[0m\u001b[1;35mPosixPath\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'/Users/jiali03/Desktop/xc392/paper-qa/docs/tutorials/papers'\u001b[0m\u001b[1m)\u001b[0m, \u001b[32m'manifest_file'\u001b[0m: \u001b[3;35mNone\u001b[0m,        \n",
       "\u001b[2;36m           \u001b[0m\u001b[32m'index_directory'\u001b[0m: \u001b[1;35mPosixPath\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'/Users/jiali03/Desktop/xc392/paper-qa/docs/tutorials/papers/index'\u001b[0m\u001b[1m)\u001b[0m,      \n",
       "\u001b[2;36m           \u001b[0m\u001b[32m'use_absolute_paper_directory'\u001b[0m: \u001b[3;91mFalse\u001b[0m, \u001b[32m'recurse_subdirectories'\u001b[0m: \u001b[3;92mTrue\u001b[0m, \u001b[32m'concurrency'\u001b[0m: \u001b[1;36m5\u001b[0m, \u001b[32m'batch_size'\u001b[0m:  \n",
       "\u001b[2;36m           \u001b[0m\u001b[1;36m1\u001b[0m, \u001b[32m'sync_with_paper_directory'\u001b[0m: \u001b[3;92mTrue\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'rebuild_index'\u001b[0m: \u001b[3;92mTrue\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'md5'\u001b[0m:                                   \n",
       "\u001b[2;36m           \u001b[0m\u001b[32m'fb017488f008b9a3f53fb44eaa50eeb3'\u001b[0m\u001b[1m}\u001b[0m.                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>New file to index: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2407.01603</span>.pdf<span style=\"color: #808000; text-decoration-color: #808000\">...</span>                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mNew file to index: \u001b[1;36m2407.01603\u001b[0m.pdf\u001b[33m...\u001b[0m                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[00:32:57] </span>CROSSREF_MAILTO environment variable not set. Crossref API rate limits may apply.                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[00:32:57]\u001b[0m\u001b[2;36m \u001b[0mCROSSREF_MAILTO environment variable not set. Crossref API rate limits may apply.                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>CROSSREF_API_KEY environment variable not set. Crossref API rate limits may apply.                      \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mCROSSREF_API_KEY environment variable not set. Crossref API rate limits may apply.                      \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>SEMANTIC_SCHOLAR_API_KEY environment variable not set. Semantic Scholar API rate limits may apply.      \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mSEMANTIC_SCHOLAR_API_KEY environment variable not set. Semantic Scholar API rate limits may apply.      \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>Metadata not found for arXiv:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2407.</span>01603v3 in CrossrefProvider.                                          \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mMetadata not found for arXiv:\u001b[1;36m2407.\u001b[0m01603v3 in CrossrefProvider.                                          \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>Metadata not found for arXiv:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2407.</span>01603v3 in SemanticScholarProvider.                                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mMetadata not found for arXiv:\u001b[1;36m2407.\u001b[0m01603v3 in SemanticScholarProvider.                                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[00:33:05] </span>Complete <span style=\"font-weight: bold\">(</span>A Review of Large Language Models and Autonomous Agents in Chemistry<span style=\"font-weight: bold\">)</span>.                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[00:33:05]\u001b[0m\u001b[2;36m \u001b[0mComplete \u001b[1m(\u001b[0mA Review of Large Language Models and Autonomous Agents in Chemistry\u001b[1m)\u001b[0m.                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[00:33:06] </span>Starting paper search for <span style=\"color: #008000; text-decoration-color: #008000\">'language models in chemistry'</span>.                                               \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[00:33:06]\u001b[0m\u001b[2;36m \u001b[0mStarting paper search for \u001b[32m'language models in chemistry'\u001b[0m.                                               \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>paper_search for query <span style=\"color: #008000; text-decoration-color: #008000\">'language models in chemistry'</span> and offset <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> returned <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> papers.                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mpaper_search for query \u001b[32m'language models in chemistry'\u001b[0m and offset \u001b[1;36m0\u001b[0m returned \u001b[1;36m1\u001b[0m papers.                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>Status: Paper <span style=\"color: #808000; text-decoration-color: #808000\">Count</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> | Relevant <span style=\"color: #808000; text-decoration-color: #808000\">Papers</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> | Current <span style=\"color: #808000; text-decoration-color: #808000\">Evidence</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> | Current <span style=\"color: #808000; text-decoration-color: #808000\">Cost</span>=$<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0001</span>                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mStatus: Paper \u001b[33mCount\u001b[0m=\u001b[1;36m1\u001b[0m | Relevant \u001b[33mPapers\u001b[0m=\u001b[1;36m0\u001b[0m | Current \u001b[33mEvidence\u001b[0m=\u001b[1;36m0\u001b[0m | Current \u001b[33mCost\u001b[0m=$\u001b[1;36m0.0001\u001b[0m                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[00:33:07] </span>gather_evidence starting for question <span style=\"color: #008000; text-decoration-color: #008000\">'What are the most relevant language models used for chemistry?'</span>. \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[00:33:07]\u001b[0m\u001b[2;36m \u001b[0mgather_evidence starting for question \u001b[32m'What are the most relevant language models used for chemistry?'\u001b[0m. \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[00:33:14] </span>Status: Paper <span style=\"color: #808000; text-decoration-color: #808000\">Count</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> | Relevant <span style=\"color: #808000; text-decoration-color: #808000\">Papers</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> | Current <span style=\"color: #808000; text-decoration-color: #808000\">Evidence</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> | Current <span style=\"color: #808000; text-decoration-color: #808000\">Cost</span>=$<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0034</span>                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[00:33:14]\u001b[0m\u001b[2;36m \u001b[0mStatus: Paper \u001b[33mCount\u001b[0m=\u001b[1;36m1\u001b[0m | Relevant \u001b[33mPapers\u001b[0m=\u001b[1;36m1\u001b[0m | Current \u001b[33mEvidence\u001b[0m=\u001b[1;36m10\u001b[0m | Current \u001b[33mCost\u001b[0m=$\u001b[1;36m0.0034\u001b[0m                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>Generating answer for <span style=\"color: #008000; text-decoration-color: #008000\">'What are the most relevant language models used for chemistry?'</span>.                 \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mGenerating answer for \u001b[32m'What are the most relevant language models used for chemistry?'\u001b[0m.                 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[00:33:20] </span>Status: Paper <span style=\"color: #808000; text-decoration-color: #808000\">Count</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> | Relevant <span style=\"color: #808000; text-decoration-color: #808000\">Papers</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> | Current <span style=\"color: #808000; text-decoration-color: #808000\">Evidence</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> | Current <span style=\"color: #808000; text-decoration-color: #808000\">Cost</span>=$<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0039</span>                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[00:33:20]\u001b[0m\u001b[2;36m \u001b[0mStatus: Paper \u001b[33mCount\u001b[0m=\u001b[1;36m1\u001b[0m | Relevant \u001b[33mPapers\u001b[0m=\u001b[1;36m1\u001b[0m | Current \u001b[33mEvidence\u001b[0m=\u001b[1;36m10\u001b[0m | Current \u001b[33mCost\u001b[0m=$\u001b[1;36m0.0039\u001b[0m                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>Completing <span style=\"color: #008000; text-decoration-color: #008000\">'What are the most relevant language models used for chemistry?'</span> as <span style=\"color: #008000; text-decoration-color: #008000\">'certain'</span>.               \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mCompleting \u001b[32m'What are the most relevant language models used for chemistry?'\u001b[0m as \u001b[32m'certain'\u001b[0m.               \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>Finished agent <span style=\"color: #008000; text-decoration-color: #008000\">'ToolSelector'</span> run with question <span style=\"color: #008000; text-decoration-color: #008000\">'What are the most relevant language models used for </span>   \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">chemistry?'</span> and status success.                                                                         \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mFinished agent \u001b[32m'ToolSelector'\u001b[0m run with question \u001b[32m'What are the most relevant language models used for \u001b[0m   \n",
       "\u001b[2;36m           \u001b[0m\u001b[32mchemistry?'\u001b[0m and status success.                                                                         \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[00:33:21] </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Answer: Several notable language models have been developed for applications in chemistry, enhancing </span>   \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">molecular design and exploration. Key models include:</span>                                                   \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                                                                                        \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">. **Text2Mol**: This model integrates natural language descriptions with molecular representations to </span> \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">improve chemical retrieval capabilities (Caldas2024 pages </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">-</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">24</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">).</span>                                       \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                                                                                        \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">. **MolT5**: Building on Text2Mol, MolT5 utilizes both SMILES (Simplified Molecular Input Line Entry </span>  \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">System) string representations and textual descriptions for generating molecular captions and predicting</span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">structures (Caldas2024 pages </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">-</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">24</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">).</span>                                                                    \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                                                                                        \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">. **iupacGPT**: Designed for property prediction and molecule generation, this model exemplifies the </span>  \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">application of large language models in chemical processes (Caldas2024 pages </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">-</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">51</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">).</span>                    \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                                                                                        \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">. **Molecular Transformer**: This model is specifically tailored for predicting chemical reactions, </span>   \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">showcasing advancements in computational methods (Caldas2024 pages </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">58</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">-</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">58</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">).</span>                              \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                                                                                        \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">. **SMILES-BERT**: Utilized for molecular property prediction, this model leverages the SMILES notation</span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">to enhance predictive capabilities (Caldas2024 pages </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">58</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">-</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">58</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">).</span>                                            \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                                                                                        \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">. **CLAMP**: This model combines chemical and language modules for biochemical predictions, </span>           \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">highlighting the trend of multimodal approaches in chemistry (Caldas2024 pages </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">-</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">24</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">).</span>                  \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                                                                                        \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">These models illustrate the significant role of large language models in transforming traditional </span>      \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">methodologies within the chemistry domain (Caldas2024 pages </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">-</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">51</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">, Caldas2024 pages </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">55</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">-</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">56</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">).</span>             \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[00:33:21]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mAnswer: Several notable language models have been developed for applications in chemistry, enhancing \u001b[0m   \n",
       "\u001b[2;36m           \u001b[0m\u001b[1;34mmolecular design and exploration. Key models include:\u001b[0m                                                   \n",
       "\u001b[2;36m           \u001b[0m                                                                                                        \n",
       "\u001b[2;36m           \u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;34m. **Text2Mol**: This model integrates natural language descriptions with molecular representations to \u001b[0m \n",
       "\u001b[2;36m           \u001b[0m\u001b[1;34mimprove chemical retrieval capabilities \u001b[0m\u001b[1;34m(\u001b[0m\u001b[1;34mCaldas2024 pages \u001b[0m\u001b[1;36m23\u001b[0m\u001b[1;34m-\u001b[0m\u001b[1;36m24\u001b[0m\u001b[1;34m)\u001b[0m\u001b[1;34m.\u001b[0m                                       \n",
       "\u001b[2;36m           \u001b[0m                                                                                                        \n",
       "\u001b[2;36m           \u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;34m. **MolT5**: Building on Text2Mol, MolT5 utilizes both SMILES \u001b[0m\u001b[1;34m(\u001b[0m\u001b[1;34mSimplified Molecular Input Line Entry \u001b[0m  \n",
       "\u001b[2;36m           \u001b[0m\u001b[1;34mSystem\u001b[0m\u001b[1;34m)\u001b[0m\u001b[1;34m string representations and textual descriptions for generating molecular captions and predicting\u001b[0m\n",
       "\u001b[2;36m           \u001b[0m\u001b[1;34mstructures \u001b[0m\u001b[1;34m(\u001b[0m\u001b[1;34mCaldas2024 pages \u001b[0m\u001b[1;36m23\u001b[0m\u001b[1;34m-\u001b[0m\u001b[1;36m24\u001b[0m\u001b[1;34m)\u001b[0m\u001b[1;34m.\u001b[0m                                                                    \n",
       "\u001b[2;36m           \u001b[0m                                                                                                        \n",
       "\u001b[2;36m           \u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;34m. **iupacGPT**: Designed for property prediction and molecule generation, this model exemplifies the \u001b[0m  \n",
       "\u001b[2;36m           \u001b[0m\u001b[1;34mapplication of large language models in chemical processes \u001b[0m\u001b[1;34m(\u001b[0m\u001b[1;34mCaldas2024 pages \u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;34m-\u001b[0m\u001b[1;36m51\u001b[0m\u001b[1;34m)\u001b[0m\u001b[1;34m.\u001b[0m                    \n",
       "\u001b[2;36m           \u001b[0m                                                                                                        \n",
       "\u001b[2;36m           \u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;34m. **Molecular Transformer**: This model is specifically tailored for predicting chemical reactions, \u001b[0m   \n",
       "\u001b[2;36m           \u001b[0m\u001b[1;34mshowcasing advancements in computational methods \u001b[0m\u001b[1;34m(\u001b[0m\u001b[1;34mCaldas2024 pages \u001b[0m\u001b[1;36m58\u001b[0m\u001b[1;34m-\u001b[0m\u001b[1;36m58\u001b[0m\u001b[1;34m)\u001b[0m\u001b[1;34m.\u001b[0m                              \n",
       "\u001b[2;36m           \u001b[0m                                                                                                        \n",
       "\u001b[2;36m           \u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;34m. **SMILES-BERT**: Utilized for molecular property prediction, this model leverages the SMILES notation\u001b[0m\n",
       "\u001b[2;36m           \u001b[0m\u001b[1;34mto enhance predictive capabilities \u001b[0m\u001b[1;34m(\u001b[0m\u001b[1;34mCaldas2024 pages \u001b[0m\u001b[1;36m58\u001b[0m\u001b[1;34m-\u001b[0m\u001b[1;36m58\u001b[0m\u001b[1;34m)\u001b[0m\u001b[1;34m.\u001b[0m                                            \n",
       "\u001b[2;36m           \u001b[0m                                                                                                        \n",
       "\u001b[2;36m           \u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;34m. **CLAMP**: This model combines chemical and language modules for biochemical predictions, \u001b[0m           \n",
       "\u001b[2;36m           \u001b[0m\u001b[1;34mhighlighting the trend of multimodal approaches in chemistry \u001b[0m\u001b[1;34m(\u001b[0m\u001b[1;34mCaldas2024 pages \u001b[0m\u001b[1;36m23\u001b[0m\u001b[1;34m-\u001b[0m\u001b[1;36m24\u001b[0m\u001b[1;34m)\u001b[0m\u001b[1;34m.\u001b[0m                  \n",
       "\u001b[2;36m           \u001b[0m                                                                                                        \n",
       "\u001b[2;36m           \u001b[0m\u001b[1;34mThese models illustrate the significant role of large language models in transforming traditional \u001b[0m      \n",
       "\u001b[2;36m           \u001b[0m\u001b[1;34mmethodologies within the chemistry domain \u001b[0m\u001b[1;34m(\u001b[0m\u001b[1;34mCaldas2024 pages \u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;34m-\u001b[0m\u001b[1;36m51\u001b[0m\u001b[1;34m, Caldas2024 pages \u001b[0m\u001b[1;36m55\u001b[0m\u001b[1;34m-\u001b[0m\u001b[1;36m56\u001b[0m\u001b[1;34m)\u001b[0m\u001b[1;34m.\u001b[0m             \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from paperqa import ask\n",
    "\n",
    "response = ask(\n",
    "    \"What are the most relevant language models used for chemistry?\", settings=settings\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which probably worked fine. Let's now try to remove `OPENAI_API_KEY` and run again the same question with the same settings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The output\n",
    "\n",
    "`Paperqa` returns a `PQASession` object, which contains not only the answer but also all the information gatheres to answer the questions. We recommend printing the `PQASession` object (`print(response.session)`) to understand the information it contains. Let's check the `PQASession` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PaperQA version: 5.21.1.dev17+g2cf0d6c\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[00:33:38] </span>Beginning agent <span style=\"color: #008000; text-decoration-color: #008000\">'ToolSelector'</span> run with question <span style=\"color: #008000; text-decoration-color: #008000\">'What are the most relevant language models used for </span>  \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">chemistry?'</span> and full settings <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'llm'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini-2024-07-18'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'llm_config'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'model_list'</span>:            \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"font-weight: bold\">[{</span><span style=\"color: #008000; text-decoration-color: #008000\">'model_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini-2024-07-18'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'litellm_params'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini-2024-07-18'</span>,         \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">'temperature'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'max_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4096</span><span style=\"font-weight: bold\">}}]</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'rate_limit'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini-2024-07-18'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'30000 per 1 </span>       \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">minute'</span><span style=\"font-weight: bold\">}}</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'summary_llm'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini-2024-07-18'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'summary_llm_config'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'rate_limit'</span>:                \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini-2024-07-18'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'30000 per 1 minute'</span><span style=\"font-weight: bold\">}}</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'embedding'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'text-embedding-3-small'</span>,               \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">'embedding_config'</span>: <span style=\"font-weight: bold\">{}</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'temperature'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'batch_size'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'texts_index_mmr_lambda'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'verbosity'</span>:\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'answer'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'evidence_k'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'evidence_detailed_citations'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'evidence_retrieval'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,        \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">'evidence_summary_length'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'about 100 words'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'evidence_skip_summary'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'answer_max_sources'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>,  \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">'max_answer_attempts'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'answer_length'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'about 200 words, but can be longer'</span>,                     \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">'max_concurrent_requests'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'answer_filter_extra_background'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'get_evidence_if_no_contexts'</span>:  \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">}</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'parsing'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'chunk_size'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5000</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'page_size_limit'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1280000</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'pdfs_use_block_parsing'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,     \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">'use_doc_details'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'overlap'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">250</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'citation_prompt'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Provide the citation for the following text</span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">in MLA Format. Do not write an introductory sentence. If reporting date accessed, the current year is </span>  \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">2025\\n\\n{text}\\n\\nCitation:'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'structured_citation_prompt'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Extract the title, authors, and doi as a </span>  \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">JSON from this MLA citation. If any field can not be found, return it as null. Use title, authors, and </span> \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">doi as keys, author's value should be a list of authors. {citation}\\n\\nCitation JSON:\"</span>,                 \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">'disable_doc_valid_check'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'defer_embedding'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'chunking_algorithm'</span>:                       \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">ChunkingOptions.SIMPLE_OVERLAP:</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span><span style=\"color: #008000; text-decoration-color: #008000\">'simple_overlap'</span><span style=\"font-weight: bold\">&gt;</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'doc_filters'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,                                \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">'use_human_readable_clinical_trials'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">}</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'prompts'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'summary'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Summarize the excerpt below to </span>   \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">help answer a question.\\n\\nExcerpt from {citation}\\n\\n----\\n\\n{text}\\n\\n----\\n\\nQuestion: </span>              \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">{question}\\n\\nDo not directly answer the question, instead summarize to give evidence to help answer the</span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">question. Stay detailed; report specific numbers, equations, or direct quotes (marked with quotation </span>   \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">marks). Reply \"Not applicable\" if the excerpt is irrelevant. At the end of your response, provide an </span>   \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">integer score from 1-10 on a newline indicating relevance to question. Do not explain your </span>             \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">score.\\n\\nRelevant Information Summary ({summary_length}):'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'qa'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Answer the question below with the </span> \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">context.\\n\\nContext (with relevance scores):\\n\\n{context}\\n\\n----\\n\\nQuestion: {question}\\n\\nWrite an </span>  \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">answer based on the context. If the context provides insufficient information reply \"I cannot answer.\" </span> \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">For each part of your answer, indicate which sources most support it via citation keys at the end of </span>   \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">sentences, like {example_citation}. Only cite from the context above and only use the citation keys from</span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">the context. ## Valid citation examples: \\n- Example2024Example pages 3-4 \\n- Example2024 pages 3-4 \\n- </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">Example2024 pages 3-4, Example2024 pages 5-6 \\n## Invalid citation examples: \\n- Example2024Example </span>    \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">pages 3-4 and pages 4-5 \\n- Example2024Example (pages 3-4) \\n- Example2024Example pages 3-4, pages 5-6 </span> \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">\\n- Example2024Example et al. (2024) \\n- Example\\'s work (pages 17–19) \\n- (pages 17–19) \\nDo not </span>      \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">concatenate citation keys, just use them as is. Write in the style of a Wikipedia article, with concise </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">sentences and coherent paragraphs. The context comes from a variety of sources and is only a summary, so</span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">there may inaccuracies or ambiguities. If quotes are present and relevant, use them in the answer. This </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">answer will go directly onto Wikipedia, so do not add any extraneous </span>                                   \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">information.\\n\\n{prior_answer_prompt}Answer ({answer_length}):'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'answer_iteration_prompt'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'You are </span>   \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">iterating on a prior answer, with a potentially different context:\\n\\n{prior_answer}\\n\\nCreate a new </span>   \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">answer only using keys and data from the included context. You can not use context keys from the prior </span> \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">answer which are not also included in the above context.\\n\\n'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'select'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Select papers that may help </span>  \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">answer the question below. Papers are listed as $KEY: $PAPER_INFO. Return a list of keys, separated by </span> \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">commas. Return \"None\", if no papers are applicable. Choose papers that are relevant, from reputable </span>    \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">sources, and timely (if the question requires timely information).\\n\\nQuestion: {question}\\n\\nPapers: </span>  \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">{papers}\\n\\nSelected keys:'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'pre'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'post'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'system'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Answer in a direct and concise tone. </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">Your audience is an expert, so be highly specific. If there are ambiguous terms or acronyms, first </span>     \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">define them.'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'use_json'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'summary_json'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Excerpt from </span>                                         \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">{citation}\\n\\n----\\n\\n{text}\\n\\n----\\n\\nQuestion: {question}\\n\\n'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'summary_json_system'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Provide a </span>   \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">summary of the relevant information that could help answer the question based on the excerpt. Respond </span>  \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">with the following JSON format:\\n\\n{{\\n  \"summary\": \"...\",\\n  \"relevance_score\": \"...\"\\n}}\\n\\nwhere </span>    \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">`summary` is relevant information from the text - {summary_length} words. `relevance_score` is an </span>      \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">integer 1-10 for the relevance of `summary` to the question.\\n'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'context_outer'</span>:                       \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">'{context_str}\\n\\nValid Keys: {valid_keys}'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'context_inner'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'{name}: {text}\\nFrom {citation}'</span><span style=\"font-weight: bold\">}</span>,       \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">'agent'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'agent_llm'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini-2024-07-18'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'agent_llm_config'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'model_list'</span>: <span style=\"font-weight: bold\">[{</span><span style=\"color: #008000; text-decoration-color: #008000\">'model_name'</span>:     \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini-2024-07-18'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'litellm_params'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'model'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini-2024-07-18'</span><span style=\"font-weight: bold\">}}]</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'rate_limit'</span>:        \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'gpt-4o-mini-2024-07-18'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'30000 per 1 minute'</span><span style=\"font-weight: bold\">}}</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'agent_type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'ToolSelector'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'agent_config'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,  \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">'agent_system_prompt'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'You are a helpful AI assistant.'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'agent_prompt'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Use the tools to answer the </span> \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">question: {question}\\n\\nWhen the answer looks sufficient, you can terminate by calling the </span>             \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">{complete_tool_name} tool. If the answer does not look sufficient, and you have already tried to answer </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">several times with different evidence, terminate by calling the {complete_tool_name} tool. The current </span> \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">status of evidence/papers/cost is {status}'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'return_paper_metadata'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'search_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>,         \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">'wipe_context_on_answer_failure'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'agent_evidence_n'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'timeout'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">500.0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'should_pre_search'</span>:   \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'tool_names'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'max_timesteps'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'index'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'name'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'paper_directory'</span>:            \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PosixPath</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'/Users/jiali03/Desktop/xc392/paper-qa/docs/tutorials/papers'</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'manifest_file'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,        \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">'index_directory'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PosixPath</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'/Users/jiali03/Desktop/xc392/paper-qa/docs/tutorials/papers/index'</span><span style=\"font-weight: bold\">)</span>,      \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">'use_absolute_paper_directory'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'recurse_subdirectories'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'concurrency'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'batch_size'</span>:  \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'sync_with_paper_directory'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">}</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'rebuild_index'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">}</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'md5'</span>:                                   \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">'fb017488f008b9a3f53fb44eaa50eeb3'</span><span style=\"font-weight: bold\">}</span>.                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[00:33:38]\u001b[0m\u001b[2;36m \u001b[0mBeginning agent \u001b[32m'ToolSelector'\u001b[0m run with question \u001b[32m'What are the most relevant language models used for \u001b[0m  \n",
       "\u001b[2;36m           \u001b[0m\u001b[32mchemistry?'\u001b[0m and full settings \u001b[1m{\u001b[0m\u001b[32m'llm'\u001b[0m: \u001b[32m'gpt-4o-mini-2024-07-18'\u001b[0m, \u001b[32m'llm_config'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'model_list'\u001b[0m:            \n",
       "\u001b[2;36m           \u001b[0m\u001b[1m[\u001b[0m\u001b[1m{\u001b[0m\u001b[32m'model_name'\u001b[0m: \u001b[32m'gpt-4o-mini-2024-07-18'\u001b[0m, \u001b[32m'litellm_params'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'model'\u001b[0m: \u001b[32m'gpt-4o-mini-2024-07-18'\u001b[0m,         \n",
       "\u001b[2;36m           \u001b[0m\u001b[32m'temperature'\u001b[0m: \u001b[1;36m0.1\u001b[0m, \u001b[32m'max_tokens'\u001b[0m: \u001b[1;36m4096\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'rate_limit'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'gpt-4o-mini-2024-07-18'\u001b[0m: \u001b[32m'30000 per 1 \u001b[0m       \n",
       "\u001b[2;36m           \u001b[0m\u001b[32mminute'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'summary_llm'\u001b[0m: \u001b[32m'gpt-4o-mini-2024-07-18'\u001b[0m, \u001b[32m'summary_llm_config'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'rate_limit'\u001b[0m:                \n",
       "\u001b[2;36m           \u001b[0m\u001b[1m{\u001b[0m\u001b[32m'gpt-4o-mini-2024-07-18'\u001b[0m: \u001b[32m'30000 per 1 minute'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'embedding'\u001b[0m: \u001b[32m'text-embedding-3-small'\u001b[0m,               \n",
       "\u001b[2;36m           \u001b[0m\u001b[32m'embedding_config'\u001b[0m: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'temperature'\u001b[0m: \u001b[1;36m0.1\u001b[0m, \u001b[32m'batch_size'\u001b[0m: \u001b[1;36m1\u001b[0m, \u001b[32m'texts_index_mmr_lambda'\u001b[0m: \u001b[1;36m1.0\u001b[0m, \u001b[32m'verbosity'\u001b[0m:\n",
       "\u001b[2;36m           \u001b[0m\u001b[1;36m1\u001b[0m, \u001b[32m'answer'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'evidence_k'\u001b[0m: \u001b[1;36m10\u001b[0m, \u001b[32m'evidence_detailed_citations'\u001b[0m: \u001b[3;92mTrue\u001b[0m, \u001b[32m'evidence_retrieval'\u001b[0m: \u001b[3;92mTrue\u001b[0m,        \n",
       "\u001b[2;36m           \u001b[0m\u001b[32m'evidence_summary_length'\u001b[0m: \u001b[32m'about 100 words'\u001b[0m, \u001b[32m'evidence_skip_summary'\u001b[0m: \u001b[3;91mFalse\u001b[0m, \u001b[32m'answer_max_sources'\u001b[0m: \u001b[1;36m5\u001b[0m,  \n",
       "\u001b[2;36m           \u001b[0m\u001b[32m'max_answer_attempts'\u001b[0m: \u001b[3;35mNone\u001b[0m, \u001b[32m'answer_length'\u001b[0m: \u001b[32m'about 200 words, but can be longer'\u001b[0m,                     \n",
       "\u001b[2;36m           \u001b[0m\u001b[32m'max_concurrent_requests'\u001b[0m: \u001b[1;36m10\u001b[0m, \u001b[32m'answer_filter_extra_background'\u001b[0m: \u001b[3;91mFalse\u001b[0m, \u001b[32m'get_evidence_if_no_contexts'\u001b[0m:  \n",
       "\u001b[2;36m           \u001b[0m\u001b[3;92mTrue\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'parsing'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'chunk_size'\u001b[0m: \u001b[1;36m5000\u001b[0m, \u001b[32m'page_size_limit'\u001b[0m: \u001b[1;36m1280000\u001b[0m, \u001b[32m'pdfs_use_block_parsing'\u001b[0m: \u001b[3;91mFalse\u001b[0m,     \n",
       "\u001b[2;36m           \u001b[0m\u001b[32m'use_doc_details'\u001b[0m: \u001b[3;92mTrue\u001b[0m, \u001b[32m'overlap'\u001b[0m: \u001b[1;36m250\u001b[0m, \u001b[32m'citation_prompt'\u001b[0m: \u001b[32m'Provide the citation for the following text\u001b[0m\n",
       "\u001b[2;36m           \u001b[0m\u001b[32min MLA Format. Do not write an introductory sentence. If reporting date accessed, the current year is \u001b[0m  \n",
       "\u001b[2;36m           \u001b[0m\u001b[32m2025\\n\\n\u001b[0m\u001b[32m{\u001b[0m\u001b[32mtext\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\\nCitation:'\u001b[0m, \u001b[32m'structured_citation_prompt'\u001b[0m: \u001b[32m\"Extract the title, authors, and doi as a \u001b[0m  \n",
       "\u001b[2;36m           \u001b[0m\u001b[32mJSON from this MLA citation. If any field can not be found, return it as null. Use title, authors, and \u001b[0m \n",
       "\u001b[2;36m           \u001b[0m\u001b[32mdoi as keys, author's value should be a list of authors. \u001b[0m\u001b[32m{\u001b[0m\u001b[32mcitation\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\\nCitation JSON:\"\u001b[0m,                 \n",
       "\u001b[2;36m           \u001b[0m\u001b[32m'disable_doc_valid_check'\u001b[0m: \u001b[3;91mFalse\u001b[0m, \u001b[32m'defer_embedding'\u001b[0m: \u001b[3;91mFalse\u001b[0m, \u001b[32m'chunking_algorithm'\u001b[0m:                       \n",
       "\u001b[2;36m           \u001b[0m\u001b[1m<\u001b[0m\u001b[1;95mChunkingOptions.SIMPLE_OVERLAP:\u001b[0m\u001b[39m \u001b[0m\u001b[32m'simple_overlap'\u001b[0m\u001b[1m>\u001b[0m, \u001b[32m'doc_filters'\u001b[0m: \u001b[3;35mNone\u001b[0m,                                \n",
       "\u001b[2;36m           \u001b[0m\u001b[32m'use_human_readable_clinical_trials'\u001b[0m: \u001b[3;91mFalse\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'prompts'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'summary'\u001b[0m: \u001b[32m'Summarize the excerpt below to \u001b[0m   \n",
       "\u001b[2;36m           \u001b[0m\u001b[32mhelp answer a question.\\n\\nExcerpt from \u001b[0m\u001b[32m{\u001b[0m\u001b[32mcitation\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\\n----\\n\\n\u001b[0m\u001b[32m{\u001b[0m\u001b[32mtext\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\\n----\\n\\nQuestion: \u001b[0m              \n",
       "\u001b[2;36m           \u001b[0m\u001b[32m{\u001b[0m\u001b[32mquestion\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\\nDo not directly answer the question, instead summarize to give evidence to help answer the\u001b[0m\n",
       "\u001b[2;36m           \u001b[0m\u001b[32mquestion. Stay detailed; report specific numbers, equations, or direct quotes \u001b[0m\u001b[32m(\u001b[0m\u001b[32mmarked with quotation \u001b[0m   \n",
       "\u001b[2;36m           \u001b[0m\u001b[32mmarks\u001b[0m\u001b[32m)\u001b[0m\u001b[32m. Reply \"Not applicable\" if the excerpt is irrelevant. At the end of your response, provide an \u001b[0m   \n",
       "\u001b[2;36m           \u001b[0m\u001b[32minteger score from 1-10 on a newline indicating relevance to question. Do not explain your \u001b[0m             \n",
       "\u001b[2;36m           \u001b[0m\u001b[32mscore.\\n\\nRelevant Information Summary \u001b[0m\u001b[32m(\u001b[0m\u001b[32m{\u001b[0m\u001b[32msummary_length\u001b[0m\u001b[32m}\u001b[0m\u001b[32m)\u001b[0m\u001b[32m:'\u001b[0m, \u001b[32m'qa'\u001b[0m: \u001b[32m'Answer the question below with the \u001b[0m \n",
       "\u001b[2;36m           \u001b[0m\u001b[32mcontext.\\n\\nContext \u001b[0m\u001b[32m(\u001b[0m\u001b[32mwith relevance scores\u001b[0m\u001b[32m)\u001b[0m\u001b[32m:\\n\\n\u001b[0m\u001b[32m{\u001b[0m\u001b[32mcontext\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\\n----\\n\\nQuestion: \u001b[0m\u001b[32m{\u001b[0m\u001b[32mquestion\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\\nWrite an \u001b[0m  \n",
       "\u001b[2;36m           \u001b[0m\u001b[32manswer based on the context. If the context provides insufficient information reply \"I cannot answer.\" \u001b[0m \n",
       "\u001b[2;36m           \u001b[0m\u001b[32mFor each part of your answer, indicate which sources most support it via citation keys at the end of \u001b[0m   \n",
       "\u001b[2;36m           \u001b[0m\u001b[32msentences, like \u001b[0m\u001b[32m{\u001b[0m\u001b[32mexample_citation\u001b[0m\u001b[32m}\u001b[0m\u001b[32m. Only cite from the context above and only use the citation keys from\u001b[0m\n",
       "\u001b[2;36m           \u001b[0m\u001b[32mthe context. ## Valid citation examples: \\n- Example2024Example pages 3-4 \\n- Example2024 pages 3-4 \\n- \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m\u001b[32mExample2024 pages 3-4, Example2024 pages 5-6 \\n## Invalid citation examples: \\n- Example2024Example \u001b[0m    \n",
       "\u001b[2;36m           \u001b[0m\u001b[32mpages 3-4 and pages 4-5 \\n- Example2024Example \u001b[0m\u001b[32m(\u001b[0m\u001b[32mpages 3-4\u001b[0m\u001b[32m)\u001b[0m\u001b[32m \\n- Example2024Example pages 3-4, pages 5-6 \u001b[0m \n",
       "\u001b[2;36m           \u001b[0m\u001b[32m\\n- Example2024Example et al. \u001b[0m\u001b[32m(\u001b[0m\u001b[32m2024\u001b[0m\u001b[32m)\u001b[0m\u001b[32m \\n- Example\\'s work \u001b[0m\u001b[32m(\u001b[0m\u001b[32mpages 17–19\u001b[0m\u001b[32m)\u001b[0m\u001b[32m \\n- \u001b[0m\u001b[32m(\u001b[0m\u001b[32mpages 17–19\u001b[0m\u001b[32m)\u001b[0m\u001b[32m \\nDo not \u001b[0m      \n",
       "\u001b[2;36m           \u001b[0m\u001b[32mconcatenate citation keys, just use them as is. Write in the style of a Wikipedia article, with concise \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m\u001b[32msentences and coherent paragraphs. The context comes from a variety of sources and is only a summary, so\u001b[0m\n",
       "\u001b[2;36m           \u001b[0m\u001b[32mthere may inaccuracies or ambiguities. If quotes are present and relevant, use them in the answer. This \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m\u001b[32manswer will go directly onto Wikipedia, so do not add any extraneous \u001b[0m                                   \n",
       "\u001b[2;36m           \u001b[0m\u001b[32minformation.\\n\\n\u001b[0m\u001b[32m{\u001b[0m\u001b[32mprior_answer_prompt\u001b[0m\u001b[32m}\u001b[0m\u001b[32mAnswer \u001b[0m\u001b[32m(\u001b[0m\u001b[32m{\u001b[0m\u001b[32manswer_length\u001b[0m\u001b[32m}\u001b[0m\u001b[32m)\u001b[0m\u001b[32m:'\u001b[0m, \u001b[32m'answer_iteration_prompt'\u001b[0m: \u001b[32m'You are \u001b[0m   \n",
       "\u001b[2;36m           \u001b[0m\u001b[32miterating on a prior answer, with a potentially different context:\\n\\n\u001b[0m\u001b[32m{\u001b[0m\u001b[32mprior_answer\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\\nCreate a new \u001b[0m   \n",
       "\u001b[2;36m           \u001b[0m\u001b[32manswer only using keys and data from the included context. You can not use context keys from the prior \u001b[0m \n",
       "\u001b[2;36m           \u001b[0m\u001b[32manswer which are not also included in the above context.\\n\\n'\u001b[0m, \u001b[32m'select'\u001b[0m: \u001b[32m'Select papers that may help \u001b[0m  \n",
       "\u001b[2;36m           \u001b[0m\u001b[32manswer the question below. Papers are listed as $KEY: $PAPER_INFO. Return a list of keys, separated by \u001b[0m \n",
       "\u001b[2;36m           \u001b[0m\u001b[32mcommas. Return \"None\", if no papers are applicable. Choose papers that are relevant, from reputable \u001b[0m    \n",
       "\u001b[2;36m           \u001b[0m\u001b[32msources, and timely \u001b[0m\u001b[32m(\u001b[0m\u001b[32mif the question requires timely information\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\n\\nQuestion: \u001b[0m\u001b[32m{\u001b[0m\u001b[32mquestion\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\\nPapers: \u001b[0m  \n",
       "\u001b[2;36m           \u001b[0m\u001b[32m{\u001b[0m\u001b[32mpapers\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\\nSelected keys:'\u001b[0m, \u001b[32m'pre'\u001b[0m: \u001b[3;35mNone\u001b[0m, \u001b[32m'post'\u001b[0m: \u001b[3;35mNone\u001b[0m, \u001b[32m'system'\u001b[0m: \u001b[32m'Answer in a direct and concise tone. \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m\u001b[32mYour audience is an expert, so be highly specific. If there are ambiguous terms or acronyms, first \u001b[0m     \n",
       "\u001b[2;36m           \u001b[0m\u001b[32mdefine them.'\u001b[0m, \u001b[32m'use_json'\u001b[0m: \u001b[3;92mTrue\u001b[0m, \u001b[32m'summary_json'\u001b[0m: \u001b[32m'Excerpt from \u001b[0m                                         \n",
       "\u001b[2;36m           \u001b[0m\u001b[32m{\u001b[0m\u001b[32mcitation\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\\n----\\n\\n\u001b[0m\u001b[32m{\u001b[0m\u001b[32mtext\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\\n----\\n\\nQuestion: \u001b[0m\u001b[32m{\u001b[0m\u001b[32mquestion\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\\n'\u001b[0m, \u001b[32m'summary_json_system'\u001b[0m: \u001b[32m'Provide a \u001b[0m   \n",
       "\u001b[2;36m           \u001b[0m\u001b[32msummary of the relevant information that could help answer the question based on the excerpt. Respond \u001b[0m  \n",
       "\u001b[2;36m           \u001b[0m\u001b[32mwith the following JSON format:\\n\\n\u001b[0m\u001b[32m{\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\n  \"summary\": \"...\",\\n  \"relevance_score\": \"...\"\\n\u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\\nwhere \u001b[0m    \n",
       "\u001b[2;36m           \u001b[0m\u001b[32m`summary` is relevant information from the text - \u001b[0m\u001b[32m{\u001b[0m\u001b[32msummary_length\u001b[0m\u001b[32m}\u001b[0m\u001b[32m words. `relevance_score` is an \u001b[0m      \n",
       "\u001b[2;36m           \u001b[0m\u001b[32minteger 1-10 for the relevance of `summary` to the question.\\n'\u001b[0m, \u001b[32m'context_outer'\u001b[0m:                       \n",
       "\u001b[2;36m           \u001b[0m\u001b[32m'\u001b[0m\u001b[32m{\u001b[0m\u001b[32mcontext_str\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\\nValid Keys: \u001b[0m\u001b[32m{\u001b[0m\u001b[32mvalid_keys\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m, \u001b[32m'context_inner'\u001b[0m: \u001b[32m'\u001b[0m\u001b[32m{\u001b[0m\u001b[32mname\u001b[0m\u001b[32m}\u001b[0m\u001b[32m: \u001b[0m\u001b[32m{\u001b[0m\u001b[32mtext\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\nFrom \u001b[0m\u001b[32m{\u001b[0m\u001b[32mcitation\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m\u001b[1m}\u001b[0m,       \n",
       "\u001b[2;36m           \u001b[0m\u001b[32m'agent'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'agent_llm'\u001b[0m: \u001b[32m'gpt-4o-mini-2024-07-18'\u001b[0m, \u001b[32m'agent_llm_config'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'model_list'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m{\u001b[0m\u001b[32m'model_name'\u001b[0m:     \n",
       "\u001b[2;36m           \u001b[0m\u001b[32m'gpt-4o-mini-2024-07-18'\u001b[0m, \u001b[32m'litellm_params'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'model'\u001b[0m: \u001b[32m'gpt-4o-mini-2024-07-18'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m\u001b[1m]\u001b[0m, \u001b[32m'rate_limit'\u001b[0m:        \n",
       "\u001b[2;36m           \u001b[0m\u001b[1m{\u001b[0m\u001b[32m'gpt-4o-mini-2024-07-18'\u001b[0m: \u001b[32m'30000 per 1 minute'\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'agent_type'\u001b[0m: \u001b[32m'ToolSelector'\u001b[0m, \u001b[32m'agent_config'\u001b[0m: \u001b[3;35mNone\u001b[0m,  \n",
       "\u001b[2;36m           \u001b[0m\u001b[32m'agent_system_prompt'\u001b[0m: \u001b[32m'You are a helpful AI assistant.'\u001b[0m, \u001b[32m'agent_prompt'\u001b[0m: \u001b[32m'Use the tools to answer the \u001b[0m \n",
       "\u001b[2;36m           \u001b[0m\u001b[32mquestion: \u001b[0m\u001b[32m{\u001b[0m\u001b[32mquestion\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n\\nWhen the answer looks sufficient, you can terminate by calling the \u001b[0m             \n",
       "\u001b[2;36m           \u001b[0m\u001b[32m{\u001b[0m\u001b[32mcomplete_tool_name\u001b[0m\u001b[32m}\u001b[0m\u001b[32m tool. If the answer does not look sufficient, and you have already tried to answer \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m\u001b[32mseveral times with different evidence, terminate by calling the \u001b[0m\u001b[32m{\u001b[0m\u001b[32mcomplete_tool_name\u001b[0m\u001b[32m}\u001b[0m\u001b[32m tool. The current \u001b[0m \n",
       "\u001b[2;36m           \u001b[0m\u001b[32mstatus of evidence/papers/cost is \u001b[0m\u001b[32m{\u001b[0m\u001b[32mstatus\u001b[0m\u001b[32m}\u001b[0m\u001b[32m'\u001b[0m, \u001b[32m'return_paper_metadata'\u001b[0m: \u001b[3;91mFalse\u001b[0m, \u001b[32m'search_count'\u001b[0m: \u001b[1;36m8\u001b[0m,         \n",
       "\u001b[2;36m           \u001b[0m\u001b[32m'wipe_context_on_answer_failure'\u001b[0m: \u001b[3;92mTrue\u001b[0m, \u001b[32m'agent_evidence_n'\u001b[0m: \u001b[1;36m1\u001b[0m, \u001b[32m'timeout'\u001b[0m: \u001b[1;36m500.0\u001b[0m, \u001b[32m'should_pre_search'\u001b[0m:   \n",
       "\u001b[2;36m           \u001b[0m\u001b[3;91mFalse\u001b[0m, \u001b[32m'tool_names'\u001b[0m: \u001b[3;35mNone\u001b[0m, \u001b[32m'max_timesteps'\u001b[0m: \u001b[3;35mNone\u001b[0m, \u001b[32m'index'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'name'\u001b[0m: \u001b[3;35mNone\u001b[0m, \u001b[32m'paper_directory'\u001b[0m:            \n",
       "\u001b[2;36m           \u001b[0m\u001b[1;35mPosixPath\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'/Users/jiali03/Desktop/xc392/paper-qa/docs/tutorials/papers'\u001b[0m\u001b[1m)\u001b[0m, \u001b[32m'manifest_file'\u001b[0m: \u001b[3;35mNone\u001b[0m,        \n",
       "\u001b[2;36m           \u001b[0m\u001b[32m'index_directory'\u001b[0m: \u001b[1;35mPosixPath\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'/Users/jiali03/Desktop/xc392/paper-qa/docs/tutorials/papers/index'\u001b[0m\u001b[1m)\u001b[0m,      \n",
       "\u001b[2;36m           \u001b[0m\u001b[32m'use_absolute_paper_directory'\u001b[0m: \u001b[3;91mFalse\u001b[0m, \u001b[32m'recurse_subdirectories'\u001b[0m: \u001b[3;92mTrue\u001b[0m, \u001b[32m'concurrency'\u001b[0m: \u001b[1;36m5\u001b[0m, \u001b[32m'batch_size'\u001b[0m:  \n",
       "\u001b[2;36m           \u001b[0m\u001b[1;36m1\u001b[0m, \u001b[32m'sync_with_paper_directory'\u001b[0m: \u001b[3;92mTrue\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'rebuild_index'\u001b[0m: \u001b[3;92mTrue\u001b[0m\u001b[1m}\u001b[0m, \u001b[32m'md5'\u001b[0m:                                   \n",
       "\u001b[2;36m           \u001b[0m\u001b[32m'fb017488f008b9a3f53fb44eaa50eeb3'\u001b[0m\u001b[1m}\u001b[0m.                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[00:33:39] </span>Starting paper search for <span style=\"color: #008000; text-decoration-color: #008000\">'language models in chemistry'</span>.                                               \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[00:33:39]\u001b[0m\u001b[2;36m \u001b[0mStarting paper search for \u001b[32m'language models in chemistry'\u001b[0m.                                               \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>paper_search for query <span style=\"color: #008000; text-decoration-color: #008000\">'language models in chemistry'</span> and offset <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> returned <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> papers.                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mpaper_search for query \u001b[32m'language models in chemistry'\u001b[0m and offset \u001b[1;36m0\u001b[0m returned \u001b[1;36m1\u001b[0m papers.                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>Status: Paper <span style=\"color: #808000; text-decoration-color: #808000\">Count</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> | Relevant <span style=\"color: #808000; text-decoration-color: #808000\">Papers</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> | Current <span style=\"color: #808000; text-decoration-color: #808000\">Evidence</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> | Current <span style=\"color: #808000; text-decoration-color: #808000\">Cost</span>=$<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0001</span>                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mStatus: Paper \u001b[33mCount\u001b[0m=\u001b[1;36m1\u001b[0m | Relevant \u001b[33mPapers\u001b[0m=\u001b[1;36m0\u001b[0m | Current \u001b[33mEvidence\u001b[0m=\u001b[1;36m0\u001b[0m | Current \u001b[33mCost\u001b[0m=$\u001b[1;36m0.0001\u001b[0m                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>gather_evidence starting for question <span style=\"color: #008000; text-decoration-color: #008000\">'What are the most relevant language models used for chemistry?'</span>. \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mgather_evidence starting for question \u001b[32m'What are the most relevant language models used for chemistry?'\u001b[0m. \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[00:34:10] </span>Status: Paper <span style=\"color: #808000; text-decoration-color: #808000\">Count</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> | Relevant <span style=\"color: #808000; text-decoration-color: #808000\">Papers</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> | Current <span style=\"color: #808000; text-decoration-color: #808000\">Evidence</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> | Current <span style=\"color: #808000; text-decoration-color: #808000\">Cost</span>=$<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0033</span>                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[00:34:10]\u001b[0m\u001b[2;36m \u001b[0mStatus: Paper \u001b[33mCount\u001b[0m=\u001b[1;36m1\u001b[0m | Relevant \u001b[33mPapers\u001b[0m=\u001b[1;36m1\u001b[0m | Current \u001b[33mEvidence\u001b[0m=\u001b[1;36m10\u001b[0m | Current \u001b[33mCost\u001b[0m=$\u001b[1;36m0.0033\u001b[0m                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[00:34:11] </span>Generating answer for <span style=\"color: #008000; text-decoration-color: #008000\">'What are the most relevant language models used for chemistry?'</span>.                 \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[00:34:11]\u001b[0m\u001b[2;36m \u001b[0mGenerating answer for \u001b[32m'What are the most relevant language models used for chemistry?'\u001b[0m.                 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[00:34:15] </span>Status: Paper <span style=\"color: #808000; text-decoration-color: #808000\">Count</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> | Relevant <span style=\"color: #808000; text-decoration-color: #808000\">Papers</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> | Current <span style=\"color: #808000; text-decoration-color: #808000\">Evidence</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span> | Current <span style=\"color: #808000; text-decoration-color: #808000\">Cost</span>=$<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0038</span>                  \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[00:34:15]\u001b[0m\u001b[2;36m \u001b[0mStatus: Paper \u001b[33mCount\u001b[0m=\u001b[1;36m1\u001b[0m | Relevant \u001b[33mPapers\u001b[0m=\u001b[1;36m1\u001b[0m | Current \u001b[33mEvidence\u001b[0m=\u001b[1;36m10\u001b[0m | Current \u001b[33mCost\u001b[0m=$\u001b[1;36m0.0038\u001b[0m                  \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[00:34:16] </span>Completing <span style=\"color: #008000; text-decoration-color: #008000\">'What are the most relevant language models used for chemistry?'</span> as <span style=\"color: #008000; text-decoration-color: #008000\">'certain'</span>.               \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[00:34:16]\u001b[0m\u001b[2;36m \u001b[0mCompleting \u001b[32m'What are the most relevant language models used for chemistry?'\u001b[0m as \u001b[32m'certain'\u001b[0m.               \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>Finished agent <span style=\"color: #008000; text-decoration-color: #008000\">'ToolSelector'</span> run with question <span style=\"color: #008000; text-decoration-color: #008000\">'What are the most relevant language models used for </span>   \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #008000; text-decoration-color: #008000\">chemistry?'</span> and status success.                                                                         \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mFinished agent \u001b[32m'ToolSelector'\u001b[0m run with question \u001b[32m'What are the most relevant language models used for \u001b[0m   \n",
       "\u001b[2;36m           \u001b[0m\u001b[32mchemistry?'\u001b[0m and status success.                                                                         \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Answer: Several language models have emerged as significant tools in the field of chemistry, each </span>      \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">addressing various challenges and applications. Notable models include Text2Mol and MolT5, which </span>       \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">integrate natural language with molecular representations, facilitating the retrieval of molecules </span>     \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">through text queries and generating molecular captions from SMILES (Simplified Molecular Input Line </span>    \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Entry System) (Caldas2024 pages </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">-</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">24</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">). </span>                                                                \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                                                                                        \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Other important models are Tag-LLM, which adapts general-purpose LLMs for specialized chemical domains, </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">and iufacGPT, designed for property prediction and molecule generation (Caldas2024 pages </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">-</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">51</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">). </span>       \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Additionally, models like MaScQA, MaterialBERT, and BatteryBERT focus on specific tasks such as </span>        \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">molecular property prediction and battery data enhancement (Caldas2024 pages </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">55</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">-</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">56</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">). </span>                   \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                                                                                        \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Attention-based neural networks and SMILES-BERT are also utilized for predicting molecular properties </span>  \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">and chemical reactions (Caldas2024 pages </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">58</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">-</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">58</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">). Furthermore, innovative approaches like a </span>             \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Teacher-Student model for multi-constraint molecular generation and text-guided models using diffusion </span> \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">techniques are enhancing data mining from chemical literature (Caldas2024 pages </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">66</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">-</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">67</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">). These </span>          \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">advancements illustrate the diverse applications of language models in improving knowledge extraction </span>  \n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">and predictive accuracy in chemistry.</span>                                                                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;34mAnswer: Several language models have emerged as significant tools in the field of chemistry, each \u001b[0m      \n",
       "\u001b[2;36m           \u001b[0m\u001b[1;34maddressing various challenges and applications. Notable models include Text2Mol and MolT5, which \u001b[0m       \n",
       "\u001b[2;36m           \u001b[0m\u001b[1;34mintegrate natural language with molecular representations, facilitating the retrieval of molecules \u001b[0m     \n",
       "\u001b[2;36m           \u001b[0m\u001b[1;34mthrough text queries and generating molecular captions from SMILES \u001b[0m\u001b[1;34m(\u001b[0m\u001b[1;34mSimplified Molecular Input Line \u001b[0m    \n",
       "\u001b[2;36m           \u001b[0m\u001b[1;34mEntry System\u001b[0m\u001b[1;34m)\u001b[0m\u001b[1;34m \u001b[0m\u001b[1;34m(\u001b[0m\u001b[1;34mCaldas2024 pages \u001b[0m\u001b[1;36m23\u001b[0m\u001b[1;34m-\u001b[0m\u001b[1;36m24\u001b[0m\u001b[1;34m)\u001b[0m\u001b[1;34m. \u001b[0m                                                                \n",
       "\u001b[2;36m           \u001b[0m                                                                                                        \n",
       "\u001b[2;36m           \u001b[0m\u001b[1;34mOther important models are Tag-LLM, which adapts general-purpose LLMs for specialized chemical domains, \u001b[0m\n",
       "\u001b[2;36m           \u001b[0m\u001b[1;34mand iufacGPT, designed for property prediction and molecule generation \u001b[0m\u001b[1;34m(\u001b[0m\u001b[1;34mCaldas2024 pages \u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;34m-\u001b[0m\u001b[1;36m51\u001b[0m\u001b[1;34m)\u001b[0m\u001b[1;34m. \u001b[0m       \n",
       "\u001b[2;36m           \u001b[0m\u001b[1;34mAdditionally, models like MaScQA, MaterialBERT, and BatteryBERT focus on specific tasks such as \u001b[0m        \n",
       "\u001b[2;36m           \u001b[0m\u001b[1;34mmolecular property prediction and battery data enhancement \u001b[0m\u001b[1;34m(\u001b[0m\u001b[1;34mCaldas2024 pages \u001b[0m\u001b[1;36m55\u001b[0m\u001b[1;34m-\u001b[0m\u001b[1;36m56\u001b[0m\u001b[1;34m)\u001b[0m\u001b[1;34m. \u001b[0m                   \n",
       "\u001b[2;36m           \u001b[0m                                                                                                        \n",
       "\u001b[2;36m           \u001b[0m\u001b[1;34mAttention-based neural networks and SMILES-BERT are also utilized for predicting molecular properties \u001b[0m  \n",
       "\u001b[2;36m           \u001b[0m\u001b[1;34mand chemical reactions \u001b[0m\u001b[1;34m(\u001b[0m\u001b[1;34mCaldas2024 pages \u001b[0m\u001b[1;36m58\u001b[0m\u001b[1;34m-\u001b[0m\u001b[1;36m58\u001b[0m\u001b[1;34m)\u001b[0m\u001b[1;34m. Furthermore, innovative approaches like a \u001b[0m             \n",
       "\u001b[2;36m           \u001b[0m\u001b[1;34mTeacher-Student model for multi-constraint molecular generation and text-guided models using diffusion \u001b[0m \n",
       "\u001b[2;36m           \u001b[0m\u001b[1;34mtechniques are enhancing data mining from chemical literature \u001b[0m\u001b[1;34m(\u001b[0m\u001b[1;34mCaldas2024 pages \u001b[0m\u001b[1;36m66\u001b[0m\u001b[1;34m-\u001b[0m\u001b[1;36m67\u001b[0m\u001b[1;34m)\u001b[0m\u001b[1;34m. These \u001b[0m          \n",
       "\u001b[2;36m           \u001b[0m\u001b[1;34madvancements illustrate the diverse applications of language models in improving knowledge extraction \u001b[0m  \n",
       "\u001b[2;36m           \u001b[0m\u001b[1;34mand predictive accuracy in chemistry.\u001b[0m                                                                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "import asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from paperqa import ask\n",
    "\n",
    "response = await ask(\n",
    "    \"What are the most relevant language models used for chemistry?\", settings=settings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What are the most relevant language models used for chemistry?\n",
      "\n",
      "Several language models have emerged as significant tools in the field of chemistry, each addressing various challenges and applications. Notable models include Text2Mol and MolT5, which integrate natural language with molecular representations, facilitating the retrieval of molecules through text queries and generating molecular captions from SMILES (Simplified Molecular Input Line Entry System) (Caldas2024 pages 23-24). \n",
      "\n",
      "Other important models are Tag-LLM, which adapts general-purpose LLMs for specialized chemical domains, and iufacGPT, designed for property prediction and molecule generation (Caldas2024 pages 50-51). Additionally, models like MaScQA, MaterialBERT, and BatteryBERT focus on specific tasks such as molecular property prediction and battery data enhancement (Caldas2024 pages 55-56). \n",
      "\n",
      "Attention-based neural networks and SMILES-BERT are also utilized for predicting molecular properties and chemical reactions (Caldas2024 pages 58-58). Furthermore, innovative approaches like a Teacher-Student model for multi-constraint molecular generation and text-guided models using diffusion techniques are enhancing data mining from chemical literature (Caldas2024 pages 66-67). These advancements illustrate the diverse applications of language models in improving knowledge extraction and predictive accuracy in chemistry.\n",
      "\n",
      "References\n",
      "\n",
      "1. (Caldas2024 pages 23-24): Caldas Ramos, Mayk, Christopher J. Collison, and Andrew D. White. \"A Review of Large Language Models and Autonomous Agents in Chemistry.\" *arXiv*, 18 Nov. 2024, arXiv:2407.01603v3. Accessed 2025.\n",
      "\n",
      "2. (Caldas2024 pages 50-51): Caldas Ramos, Mayk, Christopher J. Collison, and Andrew D. White. \"A Review of Large Language Models and Autonomous Agents in Chemistry.\" *arXiv*, 18 Nov. 2024, arXiv:2407.01603v3. Accessed 2025.\n",
      "\n",
      "3. (Caldas2024 pages 55-56): Caldas Ramos, Mayk, Christopher J. Collison, and Andrew D. White. \"A Review of Large Language Models and Autonomous Agents in Chemistry.\" *arXiv*, 18 Nov. 2024, arXiv:2407.01603v3. Accessed 2025.\n",
      "\n",
      "4. (Caldas2024 pages 58-58): Caldas Ramos, Mayk, Christopher J. Collison, and Andrew D. White. \"A Review of Large Language Models and Autonomous Agents in Chemistry.\" *arXiv*, 18 Nov. 2024, arXiv:2407.01603v3. Accessed 2025.\n",
      "\n",
      "5. (Caldas2024 pages 66-67): Caldas Ramos, Mayk, Christopher J. Collison, and Andrew D. White. \"A Review of Large Language Models and Autonomous Agents in Chemistry.\" *arXiv*, 18 Nov. 2024, arXiv:2407.01603v3. Accessed 2025.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response.session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's examine the PQASession object returned by paperqa:\n",
      "\n",
      "Status: success\n",
      "1. Question asked:\n",
      "What are the most relevant language models used for chemistry?\n",
      "\n",
      "2. Answer provided:\n",
      "Several language models have emerged as significant tools in the field of chemistry, each addressing various challenges and applications. Notable models include Text2Mol and MolT5, which integrate natural language with molecular representations, facilitating the retrieval of molecules through text queries and generating molecular captions from SMILES (Simplified Molecular Input Line Entry System) (Caldas2024 pages 23-24). \n",
      "\n",
      "Other important models are Tag-LLM, which adapts general-purpose LLMs for specialized chemical domains, and iufacGPT, designed for property prediction and molecule generation (Caldas2024 pages 50-51). Additionally, models like MaScQA, MaterialBERT, and BatteryBERT focus on specific tasks such as molecular property prediction and battery data enhancement (Caldas2024 pages 55-56). \n",
      "\n",
      "Attention-based neural networks and SMILES-BERT are also utilized for predicting molecular properties and chemical reactions (Caldas2024 pages 58-58). Furthermore, innovative approaches like a Teacher-Student model for multi-constraint molecular generation and text-guided models using diffusion techniques are enhancing data mining from chemical literature (Caldas2024 pages 66-67). These advancements illustrate the diverse applications of language models in improving knowledge extraction and predictive accuracy in chemistry.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Let's examine the PQASession object returned by paperqa:\\n\")\n",
    "\n",
    "print(f\"Status: {response.status.value}\")\n",
    "\n",
    "print(\"1. Question asked:\")\n",
    "print(f\"{response.session.question}\\n\")\n",
    "\n",
    "print(\"2. Answer provided:\")\n",
    "print(f\"{response.session.answer}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the answer, the `PQASession` object contains all the references and contexts used to generate the answer.\n",
    "\n",
    "Because `paperqa` splits the documents into chunks, each chunk is a valid reference. You can see that it also references the page where the context was found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. References cited:\n",
      "1. (Caldas2024 pages 23-24): Caldas Ramos, Mayk, Christopher J. Collison, and Andrew D. White. \"A Review of Large Language Models and Autonomous Agents in Chemistry.\" *arXiv*, 18 Nov. 2024, arXiv:2407.01603v3. Accessed 2025.\n",
      "\n",
      "2. (Caldas2024 pages 50-51): Caldas Ramos, Mayk, Christopher J. Collison, and Andrew D. White. \"A Review of Large Language Models and Autonomous Agents in Chemistry.\" *arXiv*, 18 Nov. 2024, arXiv:2407.01603v3. Accessed 2025.\n",
      "\n",
      "3. (Caldas2024 pages 55-56): Caldas Ramos, Mayk, Christopher J. Collison, and Andrew D. White. \"A Review of Large Language Models and Autonomous Agents in Chemistry.\" *arXiv*, 18 Nov. 2024, arXiv:2407.01603v3. Accessed 2025.\n",
      "\n",
      "4. (Caldas2024 pages 58-58): Caldas Ramos, Mayk, Christopher J. Collison, and Andrew D. White. \"A Review of Large Language Models and Autonomous Agents in Chemistry.\" *arXiv*, 18 Nov. 2024, arXiv:2407.01603v3. Accessed 2025.\n",
      "\n",
      "5. (Caldas2024 pages 66-67): Caldas Ramos, Mayk, Christopher J. Collison, and Andrew D. White. \"A Review of Large Language Models and Autonomous Agents in Chemistry.\" *arXiv*, 18 Nov. 2024, arXiv:2407.01603v3. Accessed 2025.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"3. References cited:\")\n",
    "print(f\"{response.session.references}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, `PQASession.session.contexts` contains the contexts used to generate the answer. Each context has a score, which is the similarity between the question and the context.\n",
    "`Paperqa` uses this score to choose what contexts is more relevant to answer the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4. Contexts used to generate the answer:\n",
      "These are the relevant text passages that were retrieved and used to formulate the answer:\n",
      "\n",
      "Context 1:\n",
      "Source: Caldas2024 pages 8-11\n",
      "Content: The excerpt discusses the integration of large language models (LLMs) in chemistry and biochemistry, focusing on various models tailored for specific tasks. Encoder-only models excel at property prediction, decoder-only models are suited for inverse design, and encoder-decoder models are used for synthesis prediction. Additionally, the content highlights the potential of decoder-only models in property prediction tasks through a reformulation as text completion tasks. The review emphasizes the importance of trustworthy datasets and robust benchmarks for effective model application in real-world chemistry situations.\n",
      "Score: 9\n",
      "\n",
      "Context 2:\n",
      "Source: Caldas2024 pages 66-67\n",
      "Content: The excerpt discusses various large language models (LLMs) that are applied in the field of chemistry, including their uses in molecular generation and data mining from chemical literature. Notable mentions include a Teacher-Student model for multi-constraint molecular generation, a text-guided molecule generation model using diffusion techniques, and models specifically designed for chemical literature data mining. References to cutting-edge studies and methodologies are made, showcasing how these language models are enhancing capabilities in extracting chemical information and properties.\n",
      "Score: 9\n",
      "\n",
      "Context 3:\n",
      "Source: Caldas2024 pages 11-12\n",
      "Content: The excerpt discusses the use of large language models (LLMs) in chemistry, specifically highlighting the model LLaMA2 which was trained on trillions of tokens. It compares the dataset size between chemistry data sources and LLaMA2, noting a disparity in token counts, particularly concerning verifiably synthesized compounds. Other notable datasets mentioned include the Mol-instructions dataset, designed for quality over quantity, and MoleculeNet, often used for benchmarking but with some limitations. The excerpt emphasizes that the lack of high-quality datasets is a significant obstacle in developing effective scientific LLMs for chemistry.\n",
      "Score: 8\n",
      "\n",
      "Context 4:\n",
      "Source: Caldas2024 pages 53-54\n",
      "Content: The excerpt contains a list of various references related to large language models (LLMs) and their application in chemistry. It discusses deep neural networks and symbolic AI for planning chemical syntheses, as highlighted by Segler et al. in 2018. Additionally, it mentions a study on whether large language models can function as superhuman chemists by Mirza et al. in 2024. These references suggest ongoing research and development in using LLMs for chemical applications, showcasing their potential role in enhancing computational chemistry workflows.\n",
      "Score: 8\n",
      "\n",
      "Context 5:\n",
      "Source: Caldas2024 pages 55-56\n",
      "Content: The excerpt references several language models relevant to chemistry, such as MaScQA, MaterialBERT, SolvBERT, and BatteryBERT. These models focus on diverse applications within the field, including molecular property prediction, solvation free energy prediction, and battery data enhancement. Other important models include MatSciBERT for text mining in materials science, and models like CatBERTa for catalyst energy prediction. The document discusses various advancements in utilizing these models to improve knowledge extraction and predictive accuracy in chemistry and materials science tasks.\n",
      "Score: 9\n",
      "\n",
      "Context 6:\n",
      "Source: Caldas2024 pages 23-24\n",
      "Content: The excerpt discusses several relevant language models for chemistry, particularly focusing on multi-modal large language models (LLMs) like Text2Mol and MolT5. Text2Mol integrates natural language descriptions with molecular representations, addressing challenges in retrieving molecules via text queries. MolT5 builds on earlier work by generating molecular captions from SMILES and predicting molecular structures from textual descriptions. Moreover, both models emphasize the need for high-quality datasets and effective metrics, indicating advancements in integrating chemical and linguistic data for applications like molecular design.\n",
      "Score: 9\n",
      "\n",
      "Context 7:\n",
      "Source: Caldas2024 pages 58-58\n",
      "Content: The excerpt references various language models and techniques relevant to chemistry, including attention-based neural networks for mapping chemical reactions, SMILES-BERT for molecular property prediction, and the Molecular Transformer for chemical reaction prediction. Additionally, it discusses models that enhance diversity for single-step retrosynthesis and deep learning approaches for predicting reaction yields. Publications such as the work by Schwaller et al. on extracting chemistry grammar and predictions using deep learning highlight significant advancements in utilizing language models in the field of chemistry.\n",
      "Score: 9\n",
      "\n",
      "Context 8:\n",
      "Source: Caldas2024 pages 76-77\n",
      "Content: The excerpt mentions several large language models (LLMs) and systems in the context of chemistry, including ChatGPT, GPT-4V, and various research frameworks like CACTUS and HuggingMolecules. These models are used for applications such as text mining, synthesis prediction, and material design optimization. Specific projects and papers showcased include 'ChatGPT Chemistry Assistant,' which focuses on MOF synthesis, and efforts to optimize crystallinity in chemical structures using ChatGPT. The emphasis is on using LLMs for advanced computational chemistry tasks and facilitating scientific discovery.\n",
      "Score: 9\n",
      "\n",
      "Context 9:\n",
      "Source: Caldas2024 pages 50-51\n",
      "Content: The excerpt references several key language models relevant to chemistry. Notable models include 'Tag-LLM,' which repurposes general-purpose LLMs for specialized domains, and 'iufacGPT,' a large-scale molecular pre-trained model geared towards property prediction and molecule generation. Additionally, large language models such as 'Cappy' enhance multi-task capabilities and 'NExT-GPT' facilitates multimodal applications. Researchers also utilize frameworks like 'Regression Transformer' for molecular language modeling, and 'Molecular Design Engines' to utilize LLMs for efficient molecular design. These models showcase a diverse range of applications within the field of chemistry.\n",
      "Score: 9\n",
      "\n",
      "Context 10:\n",
      "Source: Caldas2024 pages 62-63\n",
      "Content: The excerpt references several language models and methodologies relevant to chemistry, including Parameter-efficient fine-tuning methods for large-scale pre-trained language models and the LoRA (Low-rank adaptation) technique. It also discusses the general application of deep learning algorithms in computational chemistry and highlights the importance of innovative models like the SMILES transformer and ReactionT5 for drug discovery and reaction data analysis. Collectively, these models represent significant advancements in the integration of language models in chemical research and applications.\n",
      "Score: 8\n"
     ]
    }
   ],
   "source": [
    "print(\"4. Contexts used to generate the answer:\")\n",
    "print(\n",
    "    \"These are the relevant text passages that were retrieved and used to formulate the answer:\"\n",
    ")\n",
    "for i, ctx in enumerate(response.session.contexts, 1):\n",
    "    print(f\"\\nContext {i}:\")\n",
    "    print(f\"Source: {ctx.text.name}\")\n",
    "    print(f\"Content: {ctx.context}\")\n",
    "    print(f\"Score: {ctx.score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
