# Configuration PaperQA avec Gemini 2.x

Guide pour utiliser les **derniers mod√®les Gemini** (Gemini 2.5 Pro, 2.0 Flash, 2.0 Flash Thinking) avec PaperQA.

## üöÄ Mod√®les Gemini 2.x disponibles

### Gemini 2.5 Pro - Le plus puissant üèÜ

**Capacit√©s** :
- Raisonnement avanc√© et analyse profonde
- Contexte ultra-long (jusqu'√† 2M tokens)
- Meilleure compr√©hension multimodale
- Performances √©tat de l'art

**Usage recommand√©** :
- Recherche scientifique approfondie
- Analyse de nombreux papers complexes
- Questions n√©cessitant raisonnement multi-√©tapes
- Synth√®ses d√©taill√©es

**Configuration** : `gemini-2-5-pro.json`

---

### Gemini 2.0 Flash Thinking - Raisonnement explicite üß†

**Capacit√©s** :
- Mode "thinking" avec raisonnement visible
- Excellent pour questions complexes
- Rapide malgr√© le mode thinking
- Bon rapport qualit√©/prix

**Usage recommand√©** :
- Questions complexes n√©cessitant analyse
- Comparaisons m√©thodologiques
- Probl√®mes multi-√©tapes
- Quand vous voulez comprendre le raisonnement

**Configuration** : `gemini-2-thinking.json`

---

### Gemini 2.0 Flash - Rapide et efficace ‚ö°

**Capacit√©s** :
- Tr√®s rapide
- √âconomique
- Bonne qualit√© g√©n√©rale
- Multimodal natif

**Usage recommand√©** :
- Usage quotidien
- Questions simples √† moyennes
- Exploration rapide
- Tests

**Configuration** : `gemini-2-flash.json`

---

## üìä Comparaison d√©taill√©e

| Mod√®le | Vitesse | Qualit√© | Contexte | Co√ªt | Meilleur pour |
|--------|---------|---------|----------|------|---------------|
| **Gemini 2.5 Pro** | ‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | 2M tokens | $$$$ | Recherche approfondie |
| **Gemini 2.0 Flash Thinking** | ‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê | 1M tokens | $$ | Raisonnement complexe |
| **Gemini 2.0 Flash** | ‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê | 1M tokens | $ | Usage quotidien |
| *Gemini 1.5 Pro* | ‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê | 2M tokens | $$$ | Alternative stable |
| *Gemini 1.5 Flash* | ‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê | 1M tokens | $ | Fiable et test√© |

---

## üîß Installation avec Gemini 2.5 Pro

### √âtape 1 : Cl√© API

Obtenez votre cl√© API sur : https://makersuite.google.com/app/apikey

### √âtape 2 : Configuration

Copiez la configuration pour Gemini 2.5 Pro :

```bash
cd /home/user/paper-qa/mcp-server-paperqa
cp mcp_config.gemini-2-5-pro.json ~/.config/claude/mcp_config.json
```

### √âtape 3 : √âditer la configuration

Ouvrez `~/.config/claude/mcp_config.json` :

```json
{
  "mcpServers": {
    "paperqa": {
      "command": "paperqa-mcp",
      "env": {
        "GOOGLE_API_KEY": "AIzaSy...",  ‚Üê VOTRE CL√â
        "PAPERQA_PAPER_DIRECTORY": "/home/user/papers",
        "PAPERQA_INDEX_DIRECTORY": "/home/user/.paperqa/indexes",
        "PAPERQA_SETTINGS": "/home/user/paper-qa/mcp-server-paperqa/configs/gemini-2-5-pro.json"
      }
    }
  }
}
```

### √âtape 4 : Red√©marrer Claude Code

---

## ‚öôÔ∏è Configurations disponibles

### 1. `gemini-2-5-pro.json` - Maximum performance üèÜ

**Mod√®les** :
- LLM : `gemini/gemini-2.5-pro`
- Summary : `gemini/gemini-2.0-flash-exp`
- Embedding : `text-embedding-004`

**Param√®tres** :
- Evidence : 20 extraits
- Sources : 10 max
- R√©ponse : ~400 mots
- Search : 15 r√©sultats

**Co√ªt** : ~$0.10-0.15 par question
**Vitesse** : 30-60 secondes
**Qualit√©** : ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê

**Utiliser** :
```json
"PAPERQA_SETTINGS": "/home/user/paper-qa/mcp-server-paperqa/configs/gemini-2-5-pro.json"
```

---

### 2. `gemini-2-thinking.json` - Raisonnement explicite üß†

**Mod√®les** :
- LLM : `gemini/gemini-2.0-flash-thinking-exp`
- Summary : `gemini/gemini-2.0-flash-exp`
- Embedding : `text-embedding-004`

**Param√®tres** :
- Evidence : 12 extraits
- Sources : 6 max
- R√©ponse : ~250 mots
- Search : 10 r√©sultats

**Co√ªt** : ~$0.03-0.05 par question
**Vitesse** : 15-30 secondes
**Qualit√©** : ‚≠ê‚≠ê‚≠ê‚≠ê

**Utiliser** :
```json
"PAPERQA_SETTINGS": "/home/user/paper-qa/mcp-server-paperqa/configs/gemini-2-thinking.json"
```

---

### 3. `gemini-2-flash.json` - Rapide et efficace ‚ö°

**Mod√®les** :
- LLM : `gemini/gemini-2.0-flash-exp`
- Summary : `gemini/gemini-2.0-flash-exp`
- Embedding : `text-embedding-004`

**Param√®tres** :
- Evidence : 10 extraits
- Sources : 5 max
- R√©ponse : ~200 mots
- Search : 8 r√©sultats

**Co√ªt** : ~$0.01-0.02 par question
**Vitesse** : 5-15 secondes
**Qualit√©** : ‚≠ê‚≠ê‚≠ê

**Utiliser** :
```json
"PAPERQA_SETTINGS": "/home/user/paper-qa/mcp-server-paperqa/configs/gemini-2-flash.json"
```

---

## üéØ Quel mod√®le choisir ?

### Pour vous (Gemini 2.5 Pro) : ‚úÖ `gemini-2-5-pro.json`

**Pourquoi ?**
- Acc√®s aux capacit√©s les plus avanc√©es
- Meilleure compr√©hension des papers complexes
- R√©ponses les plus d√©taill√©es et pr√©cises
- Analyse approfondie sur plusieurs papers

**Id√©al pour** :
- Meta-analyses scientifiques
- Comparaisons de m√©thodes
- Synth√®ses de litt√©rature
- Questions n√©cessitant raisonnement profond

### Si vous voulez √©conomiser : `gemini-2-flash.json`

**Pourquoi ?**
- ~10x moins cher
- Toujours tr√®s bon
- Plus rapide
- Suffisant pour 80% des questions

### Si vous voulez voir le raisonnement : `gemini-2-thinking.json`

**Pourquoi ?**
- Mode thinking explicite
- Comprendre comment l'IA analyse
- D√©boguer des r√©ponses
- Questions complexes

---

## üß™ Exemples d'utilisation

### Avec Gemini 2.5 Pro

**Question complexe** :
```
Claude, use paperqa_ask: "Compare the methodological approaches across all papers
on protein folding in my collection. What are the key differences and which
approach shows the most promise based on empirical results?"
```

**Meta-analyse** :
```
Claude, use paperqa_ask: "Synthesize the findings from all papers about CRISPR
gene editing safety. What are the consensus points and where do researchers
disagree? Provide specific citations for each claim."
```

**Analyse temporelle** :
```
Claude, use paperqa_ask: "How have transformer architecture designs evolved
from 2017 to 2024 based on my collection? Identify key innovations and their
impact on performance."
```

### Avec Gemini 2.0 Flash Thinking

**Raisonnement multi-√©tapes** :
```
Claude, use paperqa_ask: "If I want to implement a new neural architecture
combining ideas from these papers, what are the key design choices I need to
make and what are the tradeoffs?"
```

### Avec Gemini 2.0 Flash

**Questions rapides** :
```
Claude, use paperqa_ask: "What is the main contribution of the AlphaFold paper?"
```

---

## üí° Conseils d'optimisation

### Pour Gemini 2.5 Pro

**Maximiser la qualit√©** :
```json
{
  "answer": {
    "evidence_k": 25,        // Plus d'evidence
    "max_sources": 15        // Plus de sources
  }
}
```

**Questions longues** :
- Gemini 2.5 Pro g√®re 2M tokens
- Vous pouvez poser des questions tr√®s d√©taill√©es
- Demander des analyses exhaustives

**Multimodal** :
- Peut analyser figures et tableaux
- Mieux que les versions pr√©c√©dentes

### Pour √©conomiser

**Mode √©conomique** :
```json
{
  "answer": {
    "evidence_k": 5,         // Moins d'evidence
    "max_sources": 3         // Moins de sources
  }
}
```

---

## üí∞ Co√ªts estim√©s (2024-2025)

| Mod√®le | Input (1M tokens) | Output (1M tokens) | Co√ªt/question moyen |
|--------|-------------------|-------------------|---------------------|
| Gemini 2.5 Pro | $2.50 | $10.00 | $0.10-0.15 |
| Gemini 2.0 Flash Thinking | $0.15 | $0.60 | $0.03-0.05 |
| Gemini 2.0 Flash | $0.10 | $0.40 | $0.01-0.02 |
| *Gemini 1.5 Pro* | $1.25 | $5.00 | $0.05-0.08 |
| *Gemini 1.5 Flash* | $0.075 | $0.30 | $0.01-0.02 |

*Prix indicatifs, v√©rifiez sur https://ai.google.dev/pricing*

---

## üêõ D√©pannage

### "Model gemini-2.5-pro not found"

**Cause** : Le mod√®le n'est peut-√™tre pas encore disponible dans votre r√©gion ou n√©cessite un acc√®s sp√©cial.

**Solution** :
1. V√©rifiez sur https://ai.google.dev/models/gemini
2. Utilisez `gemini-2.0-flash-exp` en attendant :
   ```json
   "llm": "gemini/gemini-2.0-flash-exp"
   ```

### "Quota exceeded"

**Cause** : Limites de taux d√©pass√©es

**Solutions** :
- Attendez quelques minutes
- Activez la facturation pour quotas plus √©lev√©s
- Utilisez un mod√®le moins sollicit√© (Flash)

### R√©ponses trop longues/courtes

**Ajuster la longueur** :
```json
{
  "answer": {
    "answer_length": "about 500 words"  // ou "100 words", etc.
  }
}
```

---

## üîÑ Migration depuis anciens mod√®les

### De Gemini 1.5 Pro ‚Üí 2.5 Pro

Changez simplement dans votre config :
```json
{
  "llm": "gemini/gemini-2.5-pro"  // au lieu de gemini-1.5-pro
}
```

**Avantages** :
- Meilleure qualit√© (+20-30%)
- Contexte maintenu (2M tokens)
- Multimodal am√©lior√©

**Co√ªt** :
- 2x plus cher mais qualit√© sup√©rieure

### De OpenAI ‚Üí Gemini 2.x

**√âquivalences** :
- GPT-4 Turbo ‚Üí Gemini 2.5 Pro
- GPT-4 ‚Üí Gemini 2.0 Flash Thinking
- GPT-3.5 Turbo ‚Üí Gemini 2.0 Flash

**Avantages de Gemini** :
- Moins cher (2-5x)
- Contexte plus long
- Multimodal natif
- Quotas plus g√©n√©reux

---

## üìö Ressources

- **Gemini API** : https://ai.google.dev/
- **Mod√®les Gemini** : https://ai.google.dev/models/gemini
- **Tarifs** : https://ai.google.dev/pricing
- **Documentation** : https://ai.google.dev/docs

---

## ‚úÖ Checklist rapide

- [ ] Cl√© API Google obtenue
- [ ] Configuration Gemini 2.5 Pro copi√©e
- [ ] `mcp_config.json` √©dit√© avec cl√© et chemins
- [ ] Dossier papers cr√©√© avec quelques PDFs
- [ ] Claude Code red√©marr√©
- [ ] Test `paperqa_get_settings` r√©ussi
- [ ] Index construit avec `paperqa_build_index`
- [ ] Premi√®re question test√©e

---

**Vous √™tes maintenant pr√™t √† utiliser PaperQA avec Gemini 2.5 Pro ! üöÄ**

Pour questions complexes n√©cessitant analyse approfondie, c'est le meilleur choix disponible.
