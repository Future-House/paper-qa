# Configurations PaperQA

Ce dossier contient des configurations pr√©d√©finies pour diff√©rents cas d'usage.

## Configurations Gemini (Google)

### S√©rie Gemini 2.x (Derni√®re g√©n√©ration) üÜï

#### `gemini-2-5-pro.json` - Maximum performance üèÜ
- **LLM** : Gemini 2.5 Pro
- **Summary** : Gemini 2.0 Flash
- **Embedding** : text-embedding-004
- **Usage** : Recherche scientifique approfondie, analyses complexes
- **Co√ªt** : ~0.10-0.15$/question
- **Vitesse** : ~30-60 secondes
- **Contexte** : 2M tokens

#### `gemini-2-thinking.json` - Raisonnement explicite üß†
- **LLM** : Gemini 2.0 Flash Thinking (experimental)
- **Summary** : Gemini 2.0 Flash
- **Embedding** : text-embedding-004
- **Usage** : Questions complexes n√©cessitant raisonnement
- **Co√ªt** : ~0.03-0.05$/question
- **Vitesse** : ~15-30 secondes

#### `gemini-2-flash.json` - Rapide et moderne ‚ö°
- **LLM** : Gemini 2.0 Flash (experimental)
- **Summary** : Gemini 2.0 Flash
- **Embedding** : text-embedding-004
- **Usage** : Usage quotidien, exploration rapide
- **Co√ªt** : ~0.01-0.02$/question
- **Vitesse** : ~5-15 secondes

### S√©rie Gemini 1.5 (Stable et test√©)

#### `gemini-fast.json` - Rapide et √©conomique ‚ö°
- **LLM** : Gemini 2.0 Flash (exp√©rimental)
- **Summary** : Gemini 2.0 Flash
- **Embedding** : text-embedding-004
- **Usage** : Tests rapides, exploration
- **Co√ªt** : ~0.01$/question
- **Vitesse** : ~5-10 secondes

#### `gemini-full.json` - √âquilibr√© (RECOMMAND√â pour d√©buter) ‚≠ê
- **LLM** : Gemini 1.5 Flash
- **Summary** : Gemini 1.5 Flash
- **Embedding** : text-embedding-004
- **Usage** : Usage quotidien
- **Co√ªt** : ~0.02$/question
- **Vitesse** : ~10-20 secondes

#### `gemini-high-quality.json` - Meilleure qualit√© 1.5
- **LLM** : Gemini 1.5 Pro
- **Summary** : Gemini 1.5 Flash
- **Embedding** : text-embedding-004
- **Usage** : Recherche approfondie
- **Co√ªt** : ~0.05$/question
- **Vitesse** : ~20-40 secondes

## Comment utiliser une configuration

### Dans votre `mcp_config.json` :

```json
{
  "mcpServers": {
    "paperqa": {
      "command": "paperqa-mcp",
      "env": {
        "GOOGLE_API_KEY": "votre-cl√©-ici",
        "PAPERQA_PAPER_DIRECTORY": "/path/to/papers",
        "PAPERQA_SETTINGS": "/home/user/paper-qa/mcp-server-paperqa/configs/gemini-full.json"
      }
    }
  }
}
```

### Changer de configuration

1. Modifiez `PAPERQA_SETTINGS` dans `mcp_config.json`
2. Red√©marrez Claude Code
3. Testez avec `paperqa_get_settings`

## Cr√©er votre propre configuration

Copiez une configuration existante :

```bash
cp gemini-full.json my-custom.json
```

√âditez `my-custom.json` selon vos besoins, puis r√©f√©rencez-le dans `mcp_config.json`.

## Param√®tres cl√©s

### LLM et Summary LLM

```json
{
  "llm": "gemini/gemini-1.5-flash",        // Mod√®le principal
  "summary_llm": "gemini/gemini-1.5-flash" // Mod√®le pour r√©sum√©s
}
```

**Mod√®les disponibles** :
- `gemini/gemini-2.5-pro` - Le plus puissant, 2M tokens contexte
- `gemini/gemini-2.0-flash-thinking-exp` - Raisonnement explicite
- `gemini/gemini-2.0-flash-exp` - Rapide et moderne, exp√©rimental
- `gemini/gemini-1.5-pro` - Stable, haute qualit√©
- `gemini/gemini-1.5-flash` - Fiable, bon rapport qualit√©/prix

### Embeddings

```json
{
  "embedding": "text-embedding-004"  // Mod√®le d'embedding Google
}
```

**Alternatives** :
- `text-embedding-3-small` (OpenAI - n√©cessite OPENAI_API_KEY)
- `text-embedding-3-large` (OpenAI - meilleur mais plus cher)

### Evidence et Sources

```json
{
  "answer": {
    "evidence_k": 10,      // Nombre d'extraits √† analyser (5-20)
    "max_sources": 5       // Nombre max de sources cit√©es (3-10)
  }
}
```

**Plus √©lev√©** = Meilleure qualit√© mais plus lent et co√ªteux

### Taille des chunks

```json
{
  "parsing": {
    "chunk_size": 3000,    // Taille des morceaux de texte (1000-5000)
    "overlap": 100         // Chevauchement entre chunks (50-200)
  }
}
```

**Plus grand** = Plus de contexte mais plus de tokens utilis√©s

## Comparaison des co√ªts

| Config | LLM | Tokens/Q | Co√ªt/Q | Vitesse | Qualit√© |
|--------|-----|----------|---------|---------|---------|
| **Gemini 2.x** | | | | | |
| gemini-2-5-pro | 2.5 Pro | ~60K | $0.10-0.15 | ‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| gemini-2-thinking | 2.0 Flash Think | ~30K | $0.03-0.05 | ‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê |
| gemini-2-flash | 2.0 Flash | ~20K | $0.01-0.02 | ‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê |
| **Gemini 1.5** | | | | | |
| gemini-fast | 2.0 Flash | ~10K | $0.01 | ‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê |
| gemini-full | 1.5 Flash | ~20K | $0.02 | ‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê |
| gemini-high-quality | 1.5 Pro | ~40K | $0.05 | ‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê |

*Q = Question

## Voir aussi

- [Configuration Gemini 1.5 compl√®te](../GEMINI_SETUP.md)
- [Configuration Gemini 2.x compl√®te](../GEMINI_2_SETUP.md) üÜï
- [Documentation PaperQA](https://github.com/Future-House/paper-qa)
- [Documentation Gemini](https://ai.google.dev/)
