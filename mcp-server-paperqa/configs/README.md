# Configurations PaperQA

Ce dossier contient des configurations pr√©d√©finies pour diff√©rents cas d'usage.

## Configurations Gemini (Google)

### `gemini-fast.json` - Rapide et √©conomique ‚ö°
- **LLM** : Gemini 2.0 Flash (exp√©rimental)
- **Summary** : Gemini 2.0 Flash
- **Embedding** : text-embedding-004
- **Usage** : Tests rapides, exploration
- **Co√ªt** : ~0.01$/question
- **Vitesse** : ~5-10 secondes

### `gemini-full.json` - √âquilibr√© (RECOMMAND√â) ‚≠ê
- **LLM** : Gemini 1.5 Flash
- **Summary** : Gemini 1.5 Flash
- **Embedding** : text-embedding-004
- **Usage** : Usage quotidien
- **Co√ªt** : ~0.02$/question
- **Vitesse** : ~10-20 secondes

### `gemini-high-quality.json` - Meilleure qualit√© üèÜ
- **LLM** : Gemini 1.5 Pro
- **Summary** : Gemini 1.5 Flash
- **Embedding** : text-embedding-004
- **Usage** : Recherche approfondie
- **Co√ªt** : ~0.05$/question
- **Vitesse** : ~20-40 secondes

## Comment utiliser une configuration

### Dans votre `mcp_config.json` :

```json
{
  "mcpServers": {
    "paperqa": {
      "command": "paperqa-mcp",
      "env": {
        "GOOGLE_API_KEY": "votre-cl√©-ici",
        "PAPERQA_PAPER_DIRECTORY": "/path/to/papers",
        "PAPERQA_SETTINGS": "/home/user/paper-qa/mcp-server-paperqa/configs/gemini-full.json"
      }
    }
  }
}
```

### Changer de configuration

1. Modifiez `PAPERQA_SETTINGS` dans `mcp_config.json`
2. Red√©marrez Claude Code
3. Testez avec `paperqa_get_settings`

## Cr√©er votre propre configuration

Copiez une configuration existante :

```bash
cp gemini-full.json my-custom.json
```

√âditez `my-custom.json` selon vos besoins, puis r√©f√©rencez-le dans `mcp_config.json`.

## Param√®tres cl√©s

### LLM et Summary LLM

```json
{
  "llm": "gemini/gemini-1.5-flash",        // Mod√®le principal
  "summary_llm": "gemini/gemini-1.5-flash" // Mod√®le pour r√©sum√©s
}
```

**Mod√®les disponibles** :
- `gemini/gemini-2.0-flash-exp` - Plus rapide, exp√©rimental
- `gemini/gemini-1.5-flash` - Fiable, bon rapport qualit√©/prix
- `gemini/gemini-1.5-pro` - Meilleure qualit√©

### Embeddings

```json
{
  "embedding": "text-embedding-004"  // Mod√®le d'embedding Google
}
```

**Alternatives** :
- `text-embedding-3-small` (OpenAI - n√©cessite OPENAI_API_KEY)
- `text-embedding-3-large` (OpenAI - meilleur mais plus cher)

### Evidence et Sources

```json
{
  "answer": {
    "evidence_k": 10,      // Nombre d'extraits √† analyser (5-20)
    "max_sources": 5       // Nombre max de sources cit√©es (3-10)
  }
}
```

**Plus √©lev√©** = Meilleure qualit√© mais plus lent et co√ªteux

### Taille des chunks

```json
{
  "parsing": {
    "chunk_size": 3000,    // Taille des morceaux de texte (1000-5000)
    "overlap": 100         // Chevauchement entre chunks (50-200)
  }
}
```

**Plus grand** = Plus de contexte mais plus de tokens utilis√©s

## Comparaison des co√ªts

| Config | LLM | Tokens/Q | Co√ªt/Q | Vitesse |
|--------|-----|----------|---------|---------|
| gemini-fast | 2.0 Flash | ~10K | $0.01 | ‚ö°‚ö°‚ö° |
| gemini-full | 1.5 Flash | ~20K | $0.02 | ‚ö°‚ö° |
| gemini-high-quality | 1.5 Pro | ~40K | $0.05 | ‚ö° |

*Q = Question

## Voir aussi

- [Configuration Gemini compl√®te](../GEMINI_SETUP.md)
- [Documentation PaperQA](https://github.com/Future-House/paper-qa)
- [Documentation Gemini](https://ai.google.dev/)
